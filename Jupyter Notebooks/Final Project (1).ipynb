{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d26a57",
   "metadata": {},
   "source": [
    "# Final Project - Predicting March Madness Tournament Winner "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c32c00",
   "metadata": {},
   "source": [
    "**Names:** Lauren Cutler, Hayden Kash, Sydney Smith\n",
    "\n",
    "**Date:** April 19, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8bceba",
   "metadata": {},
   "source": [
    "## Background and Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f33ec5",
   "metadata": {},
   "source": [
    "The reason we chose this project is because of our interest in the March Madness Tournament. We all enjoy watching the tournament every year as it is very exciting to see which college teams in the country will come out on top and be claimed as the best college basketball team. Many people every year always try to predict how the tournament will play out, so we thought why not try to actually do it by using data science. Since the NCAA is always maintaining a substantial amount of statistics on the players and teams, we thought this project would be doable as most of the data is public. Another deciding factor for choosing this project is when we present this project, the tournament will have concluded and we will be able to compare our results to who actually won."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e8d34",
   "metadata": {},
   "source": [
    "## Project Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57882753",
   "metadata": {},
   "source": [
    "The main objective is to look at multiple machine learning models to see which model performs the best in predicting the winners that advance from the round of 64 to the round of 32 and from the round of 32 to the sweet 16. In addition, we will see which model predicts the most correct teams in each round. For example, the model may predict 32 teams to advance from the round of 64 to the round of 32 but not all the 32 predicted teams will be correct. Even if not all the teams are correct if a portion of the teams continue to be correct in each of the rounds of the tournament that will help improve our bracket predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46666c34",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3005306",
   "metadata": {},
   "source": [
    "For our project, we decided to use three data domains to help predict winners in multiple rounds of the 2024 NCAA menâ€™s March Madness basketball tournament. The categories that we determined were the most essential for this project were the March Madness tournament data, the team statistics, and a power rating. Along with 2024 data we also decided to look at previous basketball seasons, to train our prediction model. The previous seasons we selected were the  2017, 2016, and 2009 seasons. The process of selecting these years was by randomly generating 3 random years between 2008-2023, as the website that holds all of the data we need only has the seasons 2008-present. Each dataset we use is in the form of a large data table on https://barttorvik.com/trank.php#, so all we needed to do was paste the data into an Excel file and convert it to a csv file. Therefore, all of the data we read for our project will be only through csv files.\n",
    "\n",
    "We started with three individual data domains for each of the four years. The tournament data contained the winners of each round of the tournament. These columns are our outcomes to predict. The teams data contained data on offensive and defensive efficiencies and turnovers. In total there were 16 statistics for team performance. The barthag column is based off of points per possession and is supposed to calculate the chance of beating a division 1 team. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d8892b",
   "metadata": {},
   "source": [
    "#### Team stats, Barthag, Tournament statistics descriptions\n",
    "\n",
    "**Breakdown of what each metric means:** \n",
    "\n",
    "- **RK** : Team Rank \n",
    "- **CONF** : Conference\n",
    "- **ADJ. EFF. OFF.** : Adjusted Offensive Efficiency \n",
    "- **ADJ. EFF. DEF.** : Adjusted Defensive Efficiency\n",
    "- **EFF. FG% OFF.** :  Effective Field Goal Percentage Offense \n",
    "- **EFF. FG% DEF.** : Effective Field Goal Percentange Deffense\n",
    "- **TURNOVER% OFF.** : Turnover Percentage Offense\n",
    "- **TURNOVER% DEF.** : Turnover Percentage Defense \n",
    "- **REB% OFF.** : Rebound Percentage Offense \n",
    "- **REB% DEF.** : Rebound Percentange Defense \n",
    "- **FT RATE OFF.** : Free Throw Rate Offense \n",
    "- **FT RATE DEF.** : Free Throw Rate Defense \n",
    "- **FT% OFF.** : Free Throw Percentage Offense \n",
    "- **FT% DEF.** : Free Throw Percentage Defense \n",
    "- **2P% OFF.** : 2 Pointer Percentage Offense\n",
    "- **2P% DEF.** : 2 Pointer Percentage Defense \n",
    "- **3P% OFF.** : 3 Pointer Percentage Offense\n",
    "- **3P% DEF.** : 3 Pointer Percentage Defense\n",
    "- **Barthag.** : Power rating (chance of beating a D1 team)\n",
    "- **PAKE** : Performance against Komputer expectations \n",
    "- **PASE** : Performance against seed expectations \n",
    "- **WINS** : Wins excluding play in games \n",
    "- **LOSS** : Losses excluding play in games\n",
    "- **W%** : Win percentage excluding play in games \n",
    "- **R64** : Appearances in the round of 64\n",
    "- **R32** : Appearances in the round of 32\n",
    "- **S16** : Appearances in the sweet 16\n",
    "- **E8** : Appearances in the elite eight\n",
    "- **F4** : Appearances in the final four\n",
    "- **F2** : Championship game appearances\n",
    "- **CHAMP** : National titles\n",
    "- **TOP2** : Years awarded a 1 or 2 seed\n",
    "- **F4%** : Likelihood of getting to at least the final 4\n",
    "- **CHAMP%** : Likelihood of winning at least 1 title per efficiency rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a66288",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf232b",
   "metadata": {},
   "source": [
    "We had to clean the teams data the most. Every other row in the teams data was a rating of that statistic. We did not want these rows in our data. Once we loaded the teams data into a pandas data frame we programmatically removed every other row. We also started with more than the 64 teams in the tournament. We reduced the teams data to the 64 teams for each year. When we tried to reduce the teams to 64 we realized that some of the team names had numbers or rankings in their names. We had to get rid of the rankings in the team names to programmatically get the list to 64. For the tournament and power rating data all we had to do was copy and paste the data from the website into excel and read in the csv file. The tournament and power rating was reduced to the 64 tournament on the website. \n",
    "\n",
    "Once we had 64 teams for each dataset for each year we worked on combining the datasets together. We combine all of previous years into one csv file in excel. This became our training data and what we first used to explore different machine learning models. Then we combine the three datasets for 2024 into one csv file. For all the data we checked to make sure the descriptive statistcs made sense, no dupilicates, and no null values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d51fd31",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5a499",
   "metadata": {},
   "source": [
    "For our exploratory analysis we started by looking at different machine learning models on the 2009, 2016, 2017 data. We looked at logistic regression, decision tree, SVM, KNN. We found that the decision tree did not perform as good as the other three models. Next, we looked at KNN, regression, SVM with the previous years as our training data and 2024 data as our test. All three models had similar accuracy so we moved forward with SVM and KNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90629b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "\n",
    "import scipy as sc\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn import tree, svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm # For regression analysis\n",
    "from sklearn import linear_model # For regression analysis\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92beef",
   "metadata": {},
   "source": [
    "### Logistic Regression exploratory analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70547f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2009, 2016, 2017 data\n",
    "data = pd.read_excel('Complete Combined Files .xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b26c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RK</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <th>TURNOVER% DEF.</th>\n",
       "      <th>OFF. REB% OFF.</th>\n",
       "      <th>...</th>\n",
       "      <th>3P% OFF.</th>\n",
       "      <th>3P% DEF.</th>\n",
       "      <th>R64</th>\n",
       "      <th>R32</th>\n",
       "      <th>S16</th>\n",
       "      <th>E8</th>\n",
       "      <th>F4</th>\n",
       "      <th>F2</th>\n",
       "      <th>CHAMP</th>\n",
       "      <th>BARTHAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206</td>\n",
       "      <td>Akron</td>\n",
       "      <td>MAC</td>\n",
       "      <td>102.9</td>\n",
       "      <td>95.6</td>\n",
       "      <td>48.1</td>\n",
       "      <td>45.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>26.4</td>\n",
       "      <td>34.3</td>\n",
       "      <td>...</td>\n",
       "      <td>33.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>American</td>\n",
       "      <td>Pat</td>\n",
       "      <td>104.2</td>\n",
       "      <td>99.9</td>\n",
       "      <td>53.7</td>\n",
       "      <td>45.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>31.5</td>\n",
       "      <td>...</td>\n",
       "      <td>37.4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>P10</td>\n",
       "      <td>118.4</td>\n",
       "      <td>101.7</td>\n",
       "      <td>53.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>18.4</td>\n",
       "      <td>35.9</td>\n",
       "      <td>...</td>\n",
       "      <td>38.7</td>\n",
       "      <td>34.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Arizona St.</td>\n",
       "      <td>P10</td>\n",
       "      <td>118.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>56.4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>29.1</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>Binghamton</td>\n",
       "      <td>AE</td>\n",
       "      <td>101.6</td>\n",
       "      <td>102.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>46.6</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.6</td>\n",
       "      <td>31.7</td>\n",
       "      <td>...</td>\n",
       "      <td>33.5</td>\n",
       "      <td>32.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RK         TEAM CONF  ADJ. EFF. OFF.  ADJ. EFF. DEF.  EFF. FG% OFF.  \\\n",
       "0  206        Akron  MAC           102.9            95.6           48.1   \n",
       "1   25     American  Pat           104.2            99.9           53.7   \n",
       "2   39      Arizona  P10           118.4           101.7           53.0   \n",
       "3    2  Arizona St.  P10           118.0            94.6           56.4   \n",
       "4  155   Binghamton   AE           101.6           102.3           49.4   \n",
       "\n",
       "   EFF. FG% DEF.  TURNOVER% OFF.  TURNOVER% DEF.  OFF. REB% OFF.  ...  \\\n",
       "0           45.5            20.7            26.4            34.3  ...   \n",
       "1           45.2            21.2            20.8            31.5  ...   \n",
       "2           51.0            19.4            18.4            35.9  ...   \n",
       "3           47.0            18.6            19.5            29.1  ...   \n",
       "4           46.6            19.7            21.6            31.7  ...   \n",
       "\n",
       "   3P% OFF.  3P% DEF.  R64  R32  S16  E8  F4  F2  CHAMP  BARTHAG  \n",
       "0      33.2      29.4    1    0    0   0   0   0      0   0.6871  \n",
       "1      37.4      33.0    1    0    0   0   0   0      0   0.4110  \n",
       "2      38.7      34.9    1    1    1   0   0   0      0   0.6002  \n",
       "3      37.0      31.9    1    1    0   0   0   0      0   0.8540  \n",
       "4      33.5      32.9    1    0    0   0   0   0      0   0.9377  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea6174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.drop(['RK','TEAM','CONF', 'R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'R64'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2b81d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <th>TURNOVER% DEF.</th>\n",
       "      <th>OFF. REB% OFF.</th>\n",
       "      <th>OFF. REB% DEF.</th>\n",
       "      <th>FT RATE OFF.</th>\n",
       "      <th>FT RATE DEF.</th>\n",
       "      <th>FT% OFF.</th>\n",
       "      <th>FT% DEF.</th>\n",
       "      <th>2P% OFF.</th>\n",
       "      <th>2P% DEF.</th>\n",
       "      <th>3P% OFF.</th>\n",
       "      <th>3P% DEF.</th>\n",
       "      <th>BARTHAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302666</td>\n",
       "      <td>0.628170</td>\n",
       "      <td>0.016115</td>\n",
       "      <td>-0.479529</td>\n",
       "      <td>-0.240984</td>\n",
       "      <td>0.161306</td>\n",
       "      <td>-0.136001</td>\n",
       "      <td>-0.102214</td>\n",
       "      <td>-0.286381</td>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.084193</td>\n",
       "      <td>0.529949</td>\n",
       "      <td>-0.034671</td>\n",
       "      <td>0.504958</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.517020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <td>-0.302666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030741</td>\n",
       "      <td>0.710293</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>-0.288723</td>\n",
       "      <td>-0.268007</td>\n",
       "      <td>0.086525</td>\n",
       "      <td>0.039824</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>0.156899</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>0.640749</td>\n",
       "      <td>0.046652</td>\n",
       "      <td>0.389342</td>\n",
       "      <td>-0.519868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <td>0.628170</td>\n",
       "      <td>0.030741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111205</td>\n",
       "      <td>-0.202413</td>\n",
       "      <td>-0.321216</td>\n",
       "      <td>-0.284749</td>\n",
       "      <td>-0.281031</td>\n",
       "      <td>-0.216726</td>\n",
       "      <td>-0.356844</td>\n",
       "      <td>0.345656</td>\n",
       "      <td>0.067115</td>\n",
       "      <td>0.867997</td>\n",
       "      <td>0.041823</td>\n",
       "      <td>0.747324</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.260174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <td>0.016115</td>\n",
       "      <td>0.710293</td>\n",
       "      <td>0.111205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.124246</td>\n",
       "      <td>-0.022969</td>\n",
       "      <td>-0.228701</td>\n",
       "      <td>0.075509</td>\n",
       "      <td>-0.016649</td>\n",
       "      <td>-0.035310</td>\n",
       "      <td>0.146895</td>\n",
       "      <td>0.117667</td>\n",
       "      <td>0.079702</td>\n",
       "      <td>0.882149</td>\n",
       "      <td>0.090346</td>\n",
       "      <td>0.575494</td>\n",
       "      <td>-0.279983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <td>-0.479529</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>-0.202413</td>\n",
       "      <td>-0.124246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215373</td>\n",
       "      <td>0.347886</td>\n",
       "      <td>0.262208</td>\n",
       "      <td>0.295497</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>-0.294047</td>\n",
       "      <td>-0.126160</td>\n",
       "      <td>-0.152853</td>\n",
       "      <td>-0.148887</td>\n",
       "      <td>-0.177384</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>-0.137656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TURNOVER% DEF.</th>\n",
       "      <td>-0.240984</td>\n",
       "      <td>-0.288723</td>\n",
       "      <td>-0.321216</td>\n",
       "      <td>-0.022969</td>\n",
       "      <td>0.215373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192090</td>\n",
       "      <td>0.489894</td>\n",
       "      <td>-0.031002</td>\n",
       "      <td>0.440002</td>\n",
       "      <td>-0.220110</td>\n",
       "      <td>-0.207003</td>\n",
       "      <td>-0.237096</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>-0.294161</td>\n",
       "      <td>-0.111957</td>\n",
       "      <td>-0.041799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFF. REB% OFF.</th>\n",
       "      <td>0.161306</td>\n",
       "      <td>-0.268007</td>\n",
       "      <td>-0.284749</td>\n",
       "      <td>-0.228701</td>\n",
       "      <td>0.347886</td>\n",
       "      <td>0.192090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162419</td>\n",
       "      <td>0.254524</td>\n",
       "      <td>0.174179</td>\n",
       "      <td>-0.229168</td>\n",
       "      <td>-0.093387</td>\n",
       "      <td>-0.190445</td>\n",
       "      <td>-0.229249</td>\n",
       "      <td>-0.245206</td>\n",
       "      <td>-0.081738</td>\n",
       "      <td>0.154509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFF. REB% DEF.</th>\n",
       "      <td>-0.136001</td>\n",
       "      <td>0.086525</td>\n",
       "      <td>-0.281031</td>\n",
       "      <td>0.075509</td>\n",
       "      <td>0.262208</td>\n",
       "      <td>0.489894</td>\n",
       "      <td>0.162419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016910</td>\n",
       "      <td>0.018560</td>\n",
       "      <td>-0.088684</td>\n",
       "      <td>-0.273650</td>\n",
       "      <td>-0.239859</td>\n",
       "      <td>0.063156</td>\n",
       "      <td>-0.228324</td>\n",
       "      <td>0.051924</td>\n",
       "      <td>-0.155250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT RATE OFF.</th>\n",
       "      <td>-0.102214</td>\n",
       "      <td>0.039824</td>\n",
       "      <td>-0.216726</td>\n",
       "      <td>-0.016649</td>\n",
       "      <td>0.295497</td>\n",
       "      <td>-0.031002</td>\n",
       "      <td>0.254524</td>\n",
       "      <td>-0.016910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.155134</td>\n",
       "      <td>-0.156552</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>-0.075807</td>\n",
       "      <td>-0.019005</td>\n",
       "      <td>-0.290404</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.121462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT RATE DEF.</th>\n",
       "      <td>-0.286381</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>-0.356844</td>\n",
       "      <td>-0.035310</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.440002</td>\n",
       "      <td>0.174179</td>\n",
       "      <td>0.018560</td>\n",
       "      <td>0.155134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200624</td>\n",
       "      <td>0.057268</td>\n",
       "      <td>-0.317084</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.243076</td>\n",
       "      <td>-0.069698</td>\n",
       "      <td>-0.097462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT% OFF.</th>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>0.345656</td>\n",
       "      <td>0.146895</td>\n",
       "      <td>-0.294047</td>\n",
       "      <td>-0.220110</td>\n",
       "      <td>-0.229168</td>\n",
       "      <td>-0.088684</td>\n",
       "      <td>-0.156552</td>\n",
       "      <td>-0.200624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151693</td>\n",
       "      <td>0.241639</td>\n",
       "      <td>0.097813</td>\n",
       "      <td>0.333594</td>\n",
       "      <td>0.127636</td>\n",
       "      <td>0.204232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT% DEF.</th>\n",
       "      <td>0.084193</td>\n",
       "      <td>0.156899</td>\n",
       "      <td>0.067115</td>\n",
       "      <td>0.117667</td>\n",
       "      <td>-0.126160</td>\n",
       "      <td>-0.207003</td>\n",
       "      <td>-0.093387</td>\n",
       "      <td>-0.273650</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.057268</td>\n",
       "      <td>0.151693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065835</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>0.156471</td>\n",
       "      <td>-0.013544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2P% OFF.</th>\n",
       "      <td>0.529949</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>0.867997</td>\n",
       "      <td>0.079702</td>\n",
       "      <td>-0.152853</td>\n",
       "      <td>-0.237096</td>\n",
       "      <td>-0.190445</td>\n",
       "      <td>-0.239859</td>\n",
       "      <td>-0.075807</td>\n",
       "      <td>-0.317084</td>\n",
       "      <td>0.241639</td>\n",
       "      <td>0.065835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048591</td>\n",
       "      <td>0.331287</td>\n",
       "      <td>0.076194</td>\n",
       "      <td>0.199560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2P% DEF.</th>\n",
       "      <td>-0.034671</td>\n",
       "      <td>0.640749</td>\n",
       "      <td>0.041823</td>\n",
       "      <td>0.882149</td>\n",
       "      <td>-0.148887</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>-0.229249</td>\n",
       "      <td>0.063156</td>\n",
       "      <td>-0.019005</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>0.097813</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>0.048591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>0.131471</td>\n",
       "      <td>-0.271281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3P% OFF.</th>\n",
       "      <td>0.504958</td>\n",
       "      <td>0.046652</td>\n",
       "      <td>0.747324</td>\n",
       "      <td>0.090346</td>\n",
       "      <td>-0.177384</td>\n",
       "      <td>-0.294161</td>\n",
       "      <td>-0.245206</td>\n",
       "      <td>-0.228324</td>\n",
       "      <td>-0.290404</td>\n",
       "      <td>-0.243076</td>\n",
       "      <td>0.333594</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>0.331287</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200114</td>\n",
       "      <td>0.223194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3P% DEF.</th>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.389342</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.575494</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>-0.111957</td>\n",
       "      <td>-0.081738</td>\n",
       "      <td>0.051924</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.069698</td>\n",
       "      <td>0.127636</td>\n",
       "      <td>0.156471</td>\n",
       "      <td>0.076194</td>\n",
       "      <td>0.131471</td>\n",
       "      <td>0.200114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.127391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARTHAG</th>\n",
       "      <td>0.517020</td>\n",
       "      <td>-0.519868</td>\n",
       "      <td>0.260174</td>\n",
       "      <td>-0.279983</td>\n",
       "      <td>-0.137656</td>\n",
       "      <td>-0.041799</td>\n",
       "      <td>0.154509</td>\n",
       "      <td>-0.155250</td>\n",
       "      <td>-0.121462</td>\n",
       "      <td>-0.097462</td>\n",
       "      <td>0.204232</td>\n",
       "      <td>-0.013544</td>\n",
       "      <td>0.199560</td>\n",
       "      <td>-0.271281</td>\n",
       "      <td>0.223194</td>\n",
       "      <td>-0.127391</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ADJ. EFF. OFF.  ADJ. EFF. DEF.  EFF. FG% OFF.  EFF. FG% DEF.  \\\n",
       "ADJ. EFF. OFF.        1.000000       -0.302666       0.628170       0.016115   \n",
       "ADJ. EFF. DEF.       -0.302666        1.000000       0.030741       0.710293   \n",
       "EFF. FG% OFF.         0.628170        0.030741       1.000000       0.111205   \n",
       "EFF. FG% DEF.         0.016115        0.710293       0.111205       1.000000   \n",
       "TURNOVER% OFF.       -0.479529        0.005809      -0.202413      -0.124246   \n",
       "TURNOVER% DEF.       -0.240984       -0.288723      -0.321216      -0.022969   \n",
       "OFF. REB% OFF.        0.161306       -0.268007      -0.284749      -0.228701   \n",
       "OFF. REB% DEF.       -0.136001        0.086525      -0.281031       0.075509   \n",
       "FT RATE OFF.         -0.102214        0.039824      -0.216726      -0.016649   \n",
       "FT RATE DEF.         -0.286381        0.004432      -0.356844      -0.035310   \n",
       "FT% OFF.              0.445124        0.031785       0.345656       0.146895   \n",
       "FT% DEF.              0.084193        0.156899       0.067115       0.117667   \n",
       "2P% OFF.              0.529949       -0.003702       0.867997       0.079702   \n",
       "2P% DEF.             -0.034671        0.640749       0.041823       0.882149   \n",
       "3P% OFF.              0.504958        0.046652       0.747324       0.090346   \n",
       "3P% DEF.              0.092774        0.389342       0.157900       0.575494   \n",
       "BARTHAG               0.517020       -0.519868       0.260174      -0.279983   \n",
       "\n",
       "                TURNOVER% OFF.  TURNOVER% DEF.  OFF. REB% OFF.  \\\n",
       "ADJ. EFF. OFF.       -0.479529       -0.240984        0.161306   \n",
       "ADJ. EFF. DEF.        0.005809       -0.288723       -0.268007   \n",
       "EFF. FG% OFF.        -0.202413       -0.321216       -0.284749   \n",
       "EFF. FG% DEF.        -0.124246       -0.022969       -0.228701   \n",
       "TURNOVER% OFF.        1.000000        0.215373        0.347886   \n",
       "TURNOVER% DEF.        0.215373        1.000000        0.192090   \n",
       "OFF. REB% OFF.        0.347886        0.192090        1.000000   \n",
       "OFF. REB% DEF.        0.262208        0.489894        0.162419   \n",
       "FT RATE OFF.          0.295497       -0.031002        0.254524   \n",
       "FT RATE DEF.          0.142056        0.440002        0.174179   \n",
       "FT% OFF.             -0.294047       -0.220110       -0.229168   \n",
       "FT% DEF.             -0.126160       -0.207003       -0.093387   \n",
       "2P% OFF.             -0.152853       -0.237096       -0.190445   \n",
       "2P% DEF.             -0.148887        0.022842       -0.229249   \n",
       "3P% OFF.             -0.177384       -0.294161       -0.245206   \n",
       "3P% DEF.             -0.002125       -0.111957       -0.081738   \n",
       "BARTHAG              -0.137656       -0.041799        0.154509   \n",
       "\n",
       "                OFF. REB% DEF.  FT RATE OFF.  FT RATE DEF.  FT% OFF.  \\\n",
       "ADJ. EFF. OFF.       -0.136001     -0.102214     -0.286381  0.445124   \n",
       "ADJ. EFF. DEF.        0.086525      0.039824      0.004432  0.031785   \n",
       "EFF. FG% OFF.        -0.281031     -0.216726     -0.356844  0.345656   \n",
       "EFF. FG% DEF.         0.075509     -0.016649     -0.035310  0.146895   \n",
       "TURNOVER% OFF.        0.262208      0.295497      0.142056 -0.294047   \n",
       "TURNOVER% DEF.        0.489894     -0.031002      0.440002 -0.220110   \n",
       "OFF. REB% OFF.        0.162419      0.254524      0.174179 -0.229168   \n",
       "OFF. REB% DEF.        1.000000     -0.016910      0.018560 -0.088684   \n",
       "FT RATE OFF.         -0.016910      1.000000      0.155134 -0.156552   \n",
       "FT RATE DEF.          0.018560      0.155134      1.000000 -0.200624   \n",
       "FT% OFF.             -0.088684     -0.156552     -0.200624  1.000000   \n",
       "FT% DEF.             -0.273650      0.003917      0.057268  0.151693   \n",
       "2P% OFF.             -0.239859     -0.075807     -0.317084  0.241639   \n",
       "2P% DEF.              0.063156     -0.019005     -0.000367  0.097813   \n",
       "3P% OFF.             -0.228324     -0.290404     -0.243076  0.333594   \n",
       "3P% DEF.              0.051924      0.008773     -0.069698  0.127636   \n",
       "BARTHAG              -0.155250     -0.121462     -0.097462  0.204232   \n",
       "\n",
       "                FT% DEF.  2P% OFF.  2P% DEF.  3P% OFF.  3P% DEF.   BARTHAG  \n",
       "ADJ. EFF. OFF.  0.084193  0.529949 -0.034671  0.504958  0.092774  0.517020  \n",
       "ADJ. EFF. DEF.  0.156899 -0.003702  0.640749  0.046652  0.389342 -0.519868  \n",
       "EFF. FG% OFF.   0.067115  0.867997  0.041823  0.747324  0.157900  0.260174  \n",
       "EFF. FG% DEF.   0.117667  0.079702  0.882149  0.090346  0.575494 -0.279983  \n",
       "TURNOVER% OFF. -0.126160 -0.152853 -0.148887 -0.177384 -0.002125 -0.137656  \n",
       "TURNOVER% DEF. -0.207003 -0.237096  0.022842 -0.294161 -0.111957 -0.041799  \n",
       "OFF. REB% OFF. -0.093387 -0.190445 -0.229249 -0.245206 -0.081738  0.154509  \n",
       "OFF. REB% DEF. -0.273650 -0.239859  0.063156 -0.228324  0.051924 -0.155250  \n",
       "FT RATE OFF.    0.003917 -0.075807 -0.019005 -0.290404  0.008773 -0.121462  \n",
       "FT RATE DEF.    0.057268 -0.317084 -0.000367 -0.243076 -0.069698 -0.097462  \n",
       "FT% OFF.        0.151693  0.241639  0.097813  0.333594  0.127636  0.204232  \n",
       "FT% DEF.        1.000000  0.065835  0.046616  0.037846  0.156471 -0.013544  \n",
       "2P% OFF.        0.065835  1.000000  0.048591  0.331287  0.076194  0.199560  \n",
       "2P% DEF.        0.046616  0.048591  1.000000 -0.001975  0.131471 -0.271281  \n",
       "3P% OFF.        0.037846  0.331287 -0.001975  1.000000  0.200114  0.223194  \n",
       "3P% DEF.        0.156471  0.076194  0.131471  0.200114  1.000000 -0.127391  \n",
       "BARTHAG        -0.013544  0.199560 -0.271281  0.223194 -0.127391  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking correlations because one of the assumptions of logistic regression is no perfect multicollinearity among independent variables.\n",
    "X.corr(method='pearson', min_periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cab2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop '2P% OFF.', 'EFF. FG% DEF.', '3P% OFF.', '2P% DEF.' because they are highly correlated \n",
    "X= data.drop(['RK','TEAM','CONF', 'R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'R64', '2P% OFF.', 'EFF. FG% DEF.', '3P% OFF.', '2P% DEF.'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa7ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data\n",
    "X= scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba2ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the round of 32\n",
    "y = data['R32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a7e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty vector of length of Complete Combined Files .xlsx to store original indexs of teams\n",
    "indices = np.arange(192)\n",
    "\n",
    "#include indices_train and indices_test to capture the original index \n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, random_state=1, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3495befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the logistic regression model on previous years combined dataset\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3660a2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77        31\n",
      "           1       0.72      0.78      0.75        27\n",
      "\n",
      "    accuracy                           0.76        58\n",
      "   macro avg       0.76      0.76      0.76        58\n",
      "weighted avg       0.76      0.76      0.76        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faaf132",
   "metadata": {},
   "source": [
    "The logistic regression model predicted with 0.76 accuracy. We continued to look at the sweet 16 and elite 8 and the accuracy continued to be high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef368bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at how well regression does with 2024 data as the test data\n",
    "\n",
    "#reading in 2024 data\n",
    "data24 = pd.read_csv('2024 Final Total Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bceca5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the same columns in the 2024 data\n",
    "X24= data24.drop(['RK','TEAM','CONF', 'R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'R64', '2P% OFF.', 'EFF. FG% DEF.', '3P% OFF.', '2P% DEF.'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10a68f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the 2024 data\n",
    "X24 = scale(X24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c419d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What we are predicting \n",
    "y = data['R32']\n",
    "y24 = data24['R32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05dc8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the test (past years) train (2024 data)\n",
    "X_train = X\n",
    "X_test = X24\n",
    "\n",
    "y_train = y\n",
    "y_test = y24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "414ef682",
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d92b43e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65        32\n",
      "           1       0.65      0.69      0.67        32\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.66      0.66      0.66        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef8004",
   "metadata": {},
   "source": [
    "The accuracy went down a little when using the 2024 data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4504d73b",
   "metadata": {},
   "source": [
    "### KNN exploratory analysis - Testing to See How Accurate the Model Can be\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1ce793",
   "metadata": {},
   "source": [
    "#### KNN Second Round Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ce3280a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of correctly predicted teams (how many there are): 74\n",
      "length of the predicted variable: 96\n",
      "Accuracy on test data = 77.08 %\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns = ['RK','TEAM','CONF', 'R64','R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP'], axis = 1) #dropping columns that have non-numeric values and that have the things we are trying to predict\n",
    "y = data['R32'] # y data is the round of 32, or what we are trying to predict \n",
    "indicies = np.arange(192) # give an index to each value \n",
    "# run the train_test_split function where we use the X & y data defined above as well as the indicies we defined so that we can find the teams\n",
    "X_Train, X_Test, y_Train, y_Test, indicies_train, indicies_test = train_test_split(X, y, indicies, random_state = 3, test_size = 0.5)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 5) # define the model and the number of neighbors, vary n_neighbors to find highest accuacy without overfitting the data \n",
    "model.fit(X_Train, y_Train) # use the model on the data \n",
    "y_pred = model.predict(X_Test) #predict !\n",
    "\n",
    "index = []\n",
    "for i in range(len(y_pred)): # loop through the length of the predicted variable \n",
    "    index.append(indicies_test[i])   #return the indicies of the predicted variable \n",
    "\n",
    "predicted_teams_real_outcome = data.iloc[index]['R32'] # return the actual outcome \n",
    "\n",
    "correctly_predicted_teams =  predicted_teams_real_outcome == y_pred # the correctly predicted teams are where the actual outcomes equal what the model predicted \n",
    "\n",
    "print('sum of correctly predicted teams (how many there are):' ,sum(correctly_predicted_teams))\n",
    "print('length of the predicted variable:', len(y_pred))\n",
    "print('Accuracy on test data = {:.2f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred)*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b2b534",
   "metadata": {},
   "source": [
    "#### KNN Sweet 16 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6a38fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of correctly predicted teams (how many there are): 72\n",
      "length of the predicted variable: 96\n",
      "Accuracy on test data = 75.00 %\n"
     ]
    }
   ],
   "source": [
    "y =  data['S16'] # set the y data to be only the sweet 16 data \n",
    "\n",
    "indicies = np.arange(192) # give an index to each value \n",
    "# run the train_test_split function where we use the X & y data defined above as well as the indicies we defined so that we can find the teams\n",
    "X_Train, X_Test, y_Train, y_Test, indicies_train, indicies_test = train_test_split(X, y, indicies, random_state = 3, test_size = 0.5)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 5) # define the model and the number of neighbors, vary n_neighbors to find highest accuacy without overfitting the data \n",
    "model.fit(X_Train, y_Train) # use the model on the data \n",
    "y_pred = model.predict(X_Test) #predict \n",
    "\n",
    "index = []\n",
    "for i in range(len(y_pred)): #loop through the length of the predicted variable \n",
    "    index.append(indicies_test[i])   #return the indicies of the predited variable \n",
    "\n",
    "predicted_teams_real_outcome = data.iloc[index]['S16'] # return the actual outcome that is defined in the data \n",
    "\n",
    "correctly_predicted_teams =  predicted_teams_real_outcome == y_pred  # the correctly predicted teams are where the actual outcomes equal what the model predicted \n",
    "\n",
    "print('sum of correctly predicted teams (how many there are):' ,sum(correctly_predicted_teams))\n",
    "print('length of the predicted variable:', len(y_pred))\n",
    "print('Accuracy on test data = {:.2f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred)*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b10b617",
   "metadata": {},
   "source": [
    "#### KNN Elite 8 Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de49862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of correctly predicted teams (how many there are): 77\n",
      "length of the predicted variable: 96\n",
      "Accuracy on test data = 80.21 %\n"
     ]
    }
   ],
   "source": [
    "y = data['E8']  # set the y data to be only elite 8 data \n",
    "\n",
    "indicies = np.arange(192) # give an index to each value \n",
    "# run the train_test_split function where we use the X & y data defined above as well as the indicies we defined so that we can find the teams\n",
    "X_Train, X_Test, y_Train, y_Test, indicies_train, indicies_test = train_test_split(X, y, indicies, random_state = 3, test_size = 0.5)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 5)  # define the model and the number of neighbors, vary n_neighbors to find highest accuacy without overfitting the data \n",
    "model.fit(X_Train, y_Train) # use the model on the data \n",
    "y_pred = model.predict(X_Test) #predict \n",
    "\n",
    "index = []\n",
    "for i in range(len(y_pred)):  #loop through the length of the predicted variable \n",
    "    index.append(indicies_test[i])   #return the indicies of the predited variable \n",
    "\n",
    "predicted_teams_real_outcome = data.iloc[index]['E8'] # return the actual outcome that is defined in the data \n",
    "\n",
    "correctly_predicted_teams =  predicted_teams_real_outcome == y_pred # the correctly predicted teams are where the actual outcomes equal what the model predicted \n",
    "\n",
    "print('sum of correctly predicted teams (how many there are):' ,sum(correctly_predicted_teams))\n",
    "print('length of the predicted variable:', len(y_pred))\n",
    "print('Accuracy on test data = {:.2f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred)*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3729b086",
   "metadata": {},
   "source": [
    "#### KNN Final 4 Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78f2b543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of correctly predicted teams (how many there are): 89\n",
      "length of the predicted variable: 96\n",
      "Accuracy on test data = 92.71 %\n"
     ]
    }
   ],
   "source": [
    "y = data['F4'] # set the y data to be only final 4 data \n",
    "indicies = np.arange(192)  # give an index to each value \n",
    "# run the train_test_split function where we use the X & y data defined above as well as the indicies we defined so that we can find the teams\n",
    "X_Train, X_Test, y_Train, y_Test, indicies_train, indicies_test = train_test_split(X, y, indicies, random_state = 3, test_size = 0.5)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 5) # define the model and the number of neighbors, vary n_neighbors to find highest accuacy without overfitting the data \n",
    "model.fit(X_Train, y_Train) # use the model on the data\n",
    "y_pred = model.predict(X_Test) #predict \n",
    "\n",
    "index = []\n",
    "for i in range(len(y_pred)): #loop through the length of the predicted variable \n",
    "    index.append(indicies_test[i])   #return the indicies of the predited variable \n",
    "\n",
    "predicted_teams_real_outcome = data.iloc[index]['F4'] # return the actual outcome that is defined in the data\n",
    "\n",
    "correctly_predicted_teams =  predicted_teams_real_outcome == y_pred # the correctly predicted teams are where the actual outcomes equal what the model predicted \n",
    "\n",
    "print('sum of correctly predicted teams (how many there are):' ,sum(correctly_predicted_teams))\n",
    "print('length of the predicted variable:', len(y_pred))\n",
    "print('Accuracy on test data = {:.2f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred)*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77745769",
   "metadata": {},
   "source": [
    "### Decision tree exploratory analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a24b9e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in 2009, 2016, 2017 data\n",
    "data = pd.read_excel('Complete Combined Files .xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ae69479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the outcome columns\n",
    "X = data.drop(columns = ['RK','TEAM','CONF', 'R64','R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP'], axis = 1)\n",
    "\n",
    "#predicting the round of 32 winners\n",
    "y = data['R32']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ed96eb",
   "metadata": {},
   "source": [
    "#### DecisionTrees Second Round Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b7bf156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correcly predicted teams = 86\n",
      "number of predicted teams = 173\n",
      "Accuracy on test data = 49.711 %\n"
     ]
    }
   ],
   "source": [
    "indicies = np.arange(192) # essentially doing the same thing as the before, creating indicies for each variable\n",
    "# run the train_test_split function where we use the X & y data defined above as well as the indicies we defined so that we can find the teams\n",
    "X_Train, X_Test, y_Train, y_Test, indicies_train, indicies_test = train_test_split(X, y, indicies, random_state = 3, test_size = 0.9)\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth = 0.7, min_samples_split = 10) # define the decision tree classifier and a max depth and minimum samples to use within the tree \n",
    "decisionTree = decisionTree.fit(X_Train, y_Train) # apply the model to the training data \n",
    "\n",
    "y_pred_test = decisionTree.predict(X_Test) # predict the variables \n",
    "y_pred_train = decisionTree.predict(X_Train)\n",
    "\n",
    "index = []\n",
    "for i in range(len(y_pred_test)): # loop throught the predicted variable \n",
    "    index.append(indicies_test[i])   # append the predicted variable index to the index variable so that we can find which teams are predicted \n",
    "\n",
    "predicted_teams_real_outcome = data.iloc[index]['R32'] # get the actual outcome from the original dataset \n",
    "\n",
    "correctly_predicted_teams =  predicted_teams_real_outcome == y_pred_test # the correctly predicted teams will be if the actual outcome equals the predcited team \n",
    "\n",
    "print('number of correcly predicted teams =', sum(correctly_predicted_teams))\n",
    "print('number of predicted teams =', len(y_pred_test))\n",
    "print('Accuracy on test data = {:.3f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred_test)*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf1d483",
   "metadata": {},
   "source": [
    "#### Decision Trees Sweet 16 Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31c5159f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correcly predicted teams = 130\n",
      "number of predicted teams = 173\n",
      "Accuracy on test data = 75.145 %\n"
     ]
    }
   ],
   "source": [
    "y = data['S16'] # set the new y variable to be the sweet 16 data from the original data set \n",
    "\n",
    "indicies = np.arange(192) # essentially doing the same thing as the before, creating indicies for each variable\n",
    "# run the train_test_split function where we use the X & y data defined above as well as the indicies we defined so that we can find the teams\n",
    "X_Train, X_Test, y_Train, y_Test, indicies_train, indicies_test = train_test_split(X, y, indicies, random_state = 3, test_size = 0.9)\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth = 0.7, min_samples_split = 10)# define the decision tree classifier and a max depth and minimum samples to use within the tree \n",
    "decisionTree = decisionTree.fit(X_Train, y_Train) # apply the model to the training data \n",
    "\n",
    "y_pred_test = decisionTree.predict(X_Test) # predict the variables \n",
    "y_pred_train = decisionTree.predict(X_Train)\n",
    "\n",
    "index = []\n",
    "for i in range(len(y_pred_test)): # loop throught the predicted variable \n",
    "    index.append(indicies_test[i])    # append the predicted variable index to the index variable so that we can find which teams are predicted \n",
    "\n",
    "predicted_teams_real_outcome = data.iloc[index]['S16'] # get the actual outcome from the original dataset \n",
    "\n",
    "correctly_predicted_teams =  predicted_teams_real_outcome == y_pred_test # the correctly predicted teams will be if the actual outcome equals the predcited team \n",
    "\n",
    "print('number of correcly predicted teams =',sum(correctly_predicted_teams))\n",
    "print('number of predicted teams =',len(y_pred_test))\n",
    "print('Accuracy on test data = {:.3f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred_test)*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107fa704",
   "metadata": {},
   "source": [
    "#### Decision Trees Elite 8 Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae2e640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of the correctly predicted teams 86\n",
      "sum of the predicted teams real outcome: 87\n",
      "number of predicted teams = 173\n",
      "Accuracy on test data = 87.86 %\n"
     ]
    }
   ],
   "source": [
    "y = data['E8'] # set the new y variable to be the sweet 16 data from the original data set \n",
    "\n",
    "indicies = np.arange(192) # essentially doing the same thing as the before, creating indicies for each variable\n",
    "# run the train_test_split function where we use the X & y data defined above as well as the indicies we defined so that we can find the teams\n",
    "X_Train, X_Test, y_Train, y_Test, indicies_train, indicies_test = train_test_split(X, y, indicies, random_state = 3, test_size = 0.9)\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth = 0.7, min_samples_split = 10) # define the decision tree classifier and a max depth and minimum samples to use within the tree \n",
    "decisionTree = decisionTree.fit(X_Train, y_Train) # apply the model to the training data \n",
    "\n",
    "y_pred_test = decisionTree.predict(X_Test) # predict the variables\n",
    "y_pred_train = decisionTree.predict(X_Train)\n",
    "\n",
    "index = []\n",
    "for i in range(len(y_pred_test)): # loop throught the predicted variable \n",
    "    index.append(indicies_test[i])   # append the predicted variable index to the index variable so that we can find which teams are predicted\n",
    "\n",
    "predicted_teams_real_outcome = data.iloc[index]['R32'] # get the actual outcome from the original dataset \n",
    "\n",
    "correctly_predicted_teams =  predicted_teams_real_outcome == y_pred_test # the correctly predicted teams will be if the actual outcome equals the predcited team \n",
    "\n",
    "print('sum of the correctly predicted teams', sum(correctly_predicted_teams))\n",
    "\n",
    "#print(list(predicted_teams_real_outcome) )\n",
    "print('sum of the predicted teams real outcome:', sum(predicted_teams_real_outcome))\n",
    "print('number of predicted teams =',len(y_pred_test))\n",
    "print('Accuracy on test data = {:.2f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred_test)*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43004af",
   "metadata": {},
   "source": [
    "**After conducting a comprehensive analysis of the Logistic Regression, KNN, and Decission Trees classification methods, our group arrived at a strategic decision to proceed with KNN. The KNN classifer consistently exhibited the highest accuracy throughout the exploration phase of our project.** \n",
    "\n",
    "**Though Logistic Regression demonstrated similiarities to KNN and SVM (explored below), it had a slightly lower accuracy. Because of this, we decided to put our focus towards KNN and SVM.** \n",
    "\n",
    "**The performance of the Decision Trees classifier was poor, as it presented challenges with accuracy and accuracy improvement. The highest accuracy that we were able to achieve with decision trees was 49.711% in the second round, indicating a suboptimal outcome akin to random guessing. When the max depth was changed within the decision trees model, we were able to achieve 100% accuracy, but that was due to overfitting within the model itself. The highest accuracy of this model occured with a maximum depth of 0.7.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f5c45",
   "metadata": {},
   "source": [
    "## Analysis Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728d7d57",
   "metadata": {},
   "source": [
    "After our exploratory analysis KNN, logistic regression, and SVM all performed similarly. We decided to move forward with KNN and SVM in our final analysis to see which is better at predicting the winners that advance from the round of 64 to the round of 32 and from the round of 32 to the sweet 16. In addition, we will look at which model predicts the most correct teams in each round. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f76cdd",
   "metadata": {},
   "source": [
    "### SVM exploratory analysis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6569b9",
   "metadata": {},
   "source": [
    "#### First Round Winners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098cdcab",
   "metadata": {},
   "source": [
    "Be sure to explain how you change C and general method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6644e4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RK</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <th>TURNOVER% DEF.</th>\n",
       "      <th>OFF. REB% OFF.</th>\n",
       "      <th>...</th>\n",
       "      <th>3P% OFF.</th>\n",
       "      <th>3P% DEF.</th>\n",
       "      <th>R64</th>\n",
       "      <th>R32</th>\n",
       "      <th>S16</th>\n",
       "      <th>E8</th>\n",
       "      <th>F4</th>\n",
       "      <th>F2</th>\n",
       "      <th>CHAMP</th>\n",
       "      <th>BARTHAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>Akron</td>\n",
       "      <td>MAC</td>\n",
       "      <td>105.1</td>\n",
       "      <td>101.8</td>\n",
       "      <td>51.7</td>\n",
       "      <td>49.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.7</td>\n",
       "      <td>29.2</td>\n",
       "      <td>...</td>\n",
       "      <td>31.7</td>\n",
       "      <td>30.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>SEC</td>\n",
       "      <td>124.9</td>\n",
       "      <td>101.7</td>\n",
       "      <td>56.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>15.9</td>\n",
       "      <td>15.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>...</td>\n",
       "      <td>36.7</td>\n",
       "      <td>31.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>P12</td>\n",
       "      <td>121.0</td>\n",
       "      <td>92.9</td>\n",
       "      <td>54.9</td>\n",
       "      <td>48.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>35.6</td>\n",
       "      <td>...</td>\n",
       "      <td>37.3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>SEC</td>\n",
       "      <td>120.9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>43.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>32.9</td>\n",
       "      <td>...</td>\n",
       "      <td>35.2</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>B12</td>\n",
       "      <td>122.5</td>\n",
       "      <td>100.8</td>\n",
       "      <td>55.7</td>\n",
       "      <td>51.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.5</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>348</td>\n",
       "      <td>Wagner</td>\n",
       "      <td>NEC</td>\n",
       "      <td>96.1</td>\n",
       "      <td>105.2</td>\n",
       "      <td>45.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>16.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>...</td>\n",
       "      <td>32.2</td>\n",
       "      <td>30.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>112</td>\n",
       "      <td>Washington St.</td>\n",
       "      <td>P12</td>\n",
       "      <td>112.9</td>\n",
       "      <td>96.5</td>\n",
       "      <td>51.8</td>\n",
       "      <td>47.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>32.9</td>\n",
       "      <td>...</td>\n",
       "      <td>33.9</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>121</td>\n",
       "      <td>Western Kentucky</td>\n",
       "      <td>CUSA</td>\n",
       "      <td>105.4</td>\n",
       "      <td>101.7</td>\n",
       "      <td>51.7</td>\n",
       "      <td>48.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>18.4</td>\n",
       "      <td>28.7</td>\n",
       "      <td>...</td>\n",
       "      <td>34.3</td>\n",
       "      <td>32.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>92</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>B10</td>\n",
       "      <td>118.6</td>\n",
       "      <td>98.9</td>\n",
       "      <td>52.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>16.9</td>\n",
       "      <td>30.2</td>\n",
       "      <td>...</td>\n",
       "      <td>34.9</td>\n",
       "      <td>36.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>95</td>\n",
       "      <td>Yale</td>\n",
       "      <td>Ivy</td>\n",
       "      <td>109.9</td>\n",
       "      <td>101.0</td>\n",
       "      <td>52.1</td>\n",
       "      <td>50.4</td>\n",
       "      <td>14.3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>27.8</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RK              TEAM  CONF  ADJ. EFF. OFF.  ADJ. EFF. DEF.  \\\n",
       "0   117             Akron   MAC           105.1           101.8   \n",
       "1    10           Alabama   SEC           124.9           101.7   \n",
       "2    24           Arizona   P12           121.0            92.9   \n",
       "3    38            Auburn   SEC           120.9            93.0   \n",
       "4    14            Baylor   B12           122.5           100.8   \n",
       "..  ...               ...   ...             ...             ...   \n",
       "59  348            Wagner   NEC            96.1           105.2   \n",
       "60  112    Washington St.   P12           112.9            96.5   \n",
       "61  121  Western Kentucky  CUSA           105.4           101.7   \n",
       "62   92         Wisconsin   B10           118.6            98.9   \n",
       "63   95              Yale   Ivy           109.9           101.0   \n",
       "\n",
       "    EFF. FG% OFF.  EFF. FG% DEF.  TURNOVER% OFF.  TURNOVER% DEF.  \\\n",
       "0            51.7           49.1            16.9            16.7   \n",
       "1            56.3           49.4            15.9            15.6   \n",
       "2            54.9           48.2            16.1            18.1   \n",
       "3            54.2           43.7            15.1            18.1   \n",
       "4            55.7           51.4            17.7            17.0   \n",
       "..            ...            ...             ...             ...   \n",
       "59           45.1           48.8            15.7            16.8   \n",
       "60           51.8           47.2            16.4            15.7   \n",
       "61           51.7           48.6            18.4            18.4   \n",
       "62           52.2           52.0            14.9            16.9   \n",
       "63           52.1           50.4            14.3            16.2   \n",
       "\n",
       "    OFF. REB% OFF.  ...  3P% OFF.  3P% DEF.  R64  R32  S16  E8  F4  F2  CHAMP  \\\n",
       "0             29.2  ...      31.7      30.7    1    0    0   0   0   0      0   \n",
       "1             34.8  ...      36.7      31.3    1    1    1   1   1   0      0   \n",
       "2             35.6  ...      37.3      33.0    1    1    1   0   0   0      0   \n",
       "3             32.9  ...      35.2      30.2    1    0    0   0   0   0      0   \n",
       "4             35.0  ...      39.5      33.4    1    1    0   0   0   0      0   \n",
       "..             ...  ...       ...       ...  ...  ...  ...  ..  ..  ..    ...   \n",
       "59            28.8  ...      32.2      30.4    1    0    0   0   0   0      0   \n",
       "60            32.9  ...      33.9      32.5    1    1    0   0   0   0      0   \n",
       "61            28.7  ...      34.3      32.4    1    0    0   0   0   0      0   \n",
       "62            30.2  ...      34.9      36.9    1    0    0   0   0   0      0   \n",
       "63            27.8  ...      35.0      34.5    1    1    0   0   0   0      0   \n",
       "\n",
       "    BARTHAG  \n",
       "0    0.6054  \n",
       "1    0.9213  \n",
       "2    0.9546  \n",
       "3    0.9563  \n",
       "4    0.9046  \n",
       "..      ...  \n",
       "59   0.2362  \n",
       "60   0.8488  \n",
       "61   0.5869  \n",
       "62   0.9006  \n",
       "63   0.7349  \n",
       "\n",
       "[64 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load combined data set of 2017,2016, and 2009 tournaments\n",
    "train_dataset = pd.read_excel(\"Complete Combined Files .xlsx\")\n",
    "#load data set of 2024 tournament\n",
    "test_dataset = pd.read_csv(\"2024 Final Total Data.csv\")\n",
    "\n",
    "# set x_train to the combined data set, but drop all columns that aren't related to a team's statistics\n",
    "X_train = train_dataset.drop([\"RK\",'TEAM',\"CONF\", \"R64\", 'R32', 'S16', 'E8', 'F4','F2','CHAMP'],axis = 1)\n",
    "# set x_test to the 2024 data set, but drop all columns that aren't related to a team's statistics\n",
    "X_test = test_dataset.drop([\"RK\",'TEAM',\"CONF\", \"R64\", 'R32', 'S16', 'E8', 'F4','F2','CHAMP'],axis = 1)\n",
    "# set y_train to the column of the winners of the first round of the combined data set\n",
    "y_train = train_dataset['R32']\n",
    "# set y_test to the column of the winners of the first round of the 2024 data set\n",
    "y_test = test_dataset['R32']\n",
    "\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a33dd0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17 15]\n",
      " [ 4 28]]\n",
      "Accuracy =  0.703125\n"
     ]
    }
   ],
   "source": [
    "# create a svm classification model\n",
    "model = svm.SVC(kernel = 'rbf',C = 5000, gamma = 'scale')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#create a confusion matrix and print overall accuracy score\n",
    "matrix = metrics.confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "print(matrix)\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_true = y_test, y_pred = model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc34ed42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "43\n",
      "['Alabama', 'Arizona', 'Auburn', 'Baylor', 'BYU', 'Clemson', 'Colorado', 'Colorado St.', 'Connecticut', 'Creighton', 'Dayton', 'Drake', 'Duke', 'Florida', 'Florida Atlantic', 'Gonzaga', 'Houston', 'Illinois', 'Iowa St.', 'James Madison', 'Kansas', 'Kentucky', 'Marquette', 'Michigan St.', 'Mississippi St.', 'Nebraska', 'Nevada', 'New Mexico', 'North Carolina', 'North Carolina St.', 'Northwestern', 'Oregon', 'Purdue', \"Saint Mary's\", 'San Diego St.', 'TCU', 'Tennessee', 'Texas', 'Texas A&M', 'Texas Tech', 'Utah St.', 'Washington St.', 'Wisconsin']\n"
     ]
    }
   ],
   "source": [
    "# find out which teams the model predicted on winning in the first round\n",
    "\n",
    "predicted_winners = []\n",
    "\n",
    "# put the index numbers of the predicted winners into an array\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_pred[i] == 1):\n",
    "        predicted_winners.append(i)\n",
    "        \n",
    "print(len(predicted_winners))\n",
    "\n",
    "\n",
    "predicted_team_winners = []\n",
    "\n",
    "# go through the 2024 data set and find the names of the next predicted winners by using their index numbers.\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    for index in predicted_winners:\n",
    "        if (i == index):\n",
    "            predicted_team_winners.append(test_dataset[\"TEAM\"][i])\n",
    "    \n",
    "print(len(predicted_team_winners))\n",
    "print(list(predicted_team_winners))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3230e",
   "metadata": {},
   "source": [
    "#### Second Round Winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2d85353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>RK</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <th>TURNOVER% DEF.</th>\n",
       "      <th>...</th>\n",
       "      <th>3P% OFF.</th>\n",
       "      <th>3P% DEF.</th>\n",
       "      <th>R64</th>\n",
       "      <th>R32</th>\n",
       "      <th>S16</th>\n",
       "      <th>E8</th>\n",
       "      <th>F4</th>\n",
       "      <th>F2</th>\n",
       "      <th>CHAMP</th>\n",
       "      <th>BARTHAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>SEC</td>\n",
       "      <td>124.9</td>\n",
       "      <td>101.7</td>\n",
       "      <td>56.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>15.9</td>\n",
       "      <td>15.6</td>\n",
       "      <td>...</td>\n",
       "      <td>36.7</td>\n",
       "      <td>31.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>P12</td>\n",
       "      <td>121.0</td>\n",
       "      <td>92.9</td>\n",
       "      <td>54.9</td>\n",
       "      <td>48.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>...</td>\n",
       "      <td>37.3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>SEC</td>\n",
       "      <td>120.9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>43.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>...</td>\n",
       "      <td>35.2</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>B12</td>\n",
       "      <td>122.5</td>\n",
       "      <td>100.8</td>\n",
       "      <td>55.7</td>\n",
       "      <td>51.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.5</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>BYU</td>\n",
       "      <td>B12</td>\n",
       "      <td>119.8</td>\n",
       "      <td>99.7</td>\n",
       "      <td>54.8</td>\n",
       "      <td>48.2</td>\n",
       "      <td>15.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.8</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  RK     TEAM CONF  ADJ. EFF. OFF.  ADJ. EFF. DEF.  EFF. FG% OFF.  \\\n",
       "0      1  10  Alabama  SEC           124.9           101.7           56.3   \n",
       "1      2  24  Arizona  P12           121.0            92.9           54.9   \n",
       "2      3  38   Auburn  SEC           120.9            93.0           54.2   \n",
       "3      4  14   Baylor  B12           122.5           100.8           55.7   \n",
       "4      5  25      BYU  B12           119.8            99.7           54.8   \n",
       "\n",
       "   EFF. FG% DEF.  TURNOVER% OFF.  TURNOVER% DEF.  ...  3P% OFF.  3P% DEF.  \\\n",
       "0           49.4            15.9            15.6  ...      36.7      31.3   \n",
       "1           48.2            16.1            18.1  ...      37.3      33.0   \n",
       "2           43.7            15.1            18.1  ...      35.2      30.2   \n",
       "3           51.4            17.7            17.0  ...      39.5      33.4   \n",
       "4           48.2            15.3            16.0  ...      34.8      32.0   \n",
       "\n",
       "   R64  R32  S16  E8  F4  F2  CHAMP  BARTHAG  \n",
       "0    1    1    1   1   1   0      0   0.9213  \n",
       "1    1    1    1   0   0   0      0   0.9546  \n",
       "2    1    0    0   0   0   0      0   0.9563  \n",
       "3    1    1    0   0   0   0      0   0.9046  \n",
       "4    1    0    0   0   0   0      0   0.9087  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new data frame that filters out the losers of the first round so we can just have the winners\n",
    "second_round_test_dataset = test_dataset.loc[predicted_winners]\n",
    "# reset the index numbers\n",
    "second_round_test_dataset = second_round_test_dataset.reset_index()\n",
    "# set y_train to the column of the actual winners of the second round of the combined data set\n",
    "y_train = train_dataset['S16']\n",
    "# set y_test to the column of the winners of the second round of the 2024 data set\n",
    "y_test = second_round_test_dataset['S16']\n",
    "# set x_test to the winners of the first round, but drop all columns that aren't related to a team's statistics\n",
    "X_test = second_round_test_dataset.drop([\"RK\",'TEAM',\"CONF\", \"R64\", 'R32', 'S16', 'E8', 'F4','F2','CHAMP', 'index'],axis = 1)\n",
    "second_round_test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d56d82b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  4]\n",
      " [ 8  8]]\n",
      "Accuracy =  0.7209302325581395\n"
     ]
    }
   ],
   "source": [
    "# create a svm classification model\n",
    "model = svm.SVC(kernel = 'rbf',C = 2500, gamma = 'scale')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#create a confusion matrix and print overall accuracy score\n",
    "matrix = metrics.confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "print(matrix)\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_true = y_test, y_pred = model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46660c73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "['Arizona', 'Baylor', 'Colorado', 'Connecticut', 'Duke', 'Gonzaga', 'Houston', 'Illinois', 'Iowa St.', 'Kansas', 'Purdue', 'Wisconsin']\n"
     ]
    }
   ],
   "source": [
    "# find out which teams the model predicted on winning in the second round\n",
    "\n",
    "predicted_winners = []\n",
    "\n",
    "# put the index numbers of the predicted winners into an array\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_pred[i] == 1):\n",
    "        predicted_winners.append(i)\n",
    "        \n",
    "print(len(predicted_winners))\n",
    "\n",
    "\n",
    "predicted_team_winners = []\n",
    "\n",
    "# go through the first round winners and find the names of the next predicted winners by using their index numbers.\n",
    "for i in range(len(second_round_test_dataset)):\n",
    "    for index in predicted_winners:\n",
    "        if (i == index):\n",
    "            predicted_team_winners.append(second_round_test_dataset[\"TEAM\"][i])\n",
    "    \n",
    "print(len(predicted_team_winners))\n",
    "print(list(predicted_team_winners))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a3a431",
   "metadata": {},
   "source": [
    "#### Sweet 16 Winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42b7aa7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>RK</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <th>...</th>\n",
       "      <th>3P% OFF.</th>\n",
       "      <th>3P% DEF.</th>\n",
       "      <th>R64</th>\n",
       "      <th>R32</th>\n",
       "      <th>S16</th>\n",
       "      <th>E8</th>\n",
       "      <th>F4</th>\n",
       "      <th>F2</th>\n",
       "      <th>CHAMP</th>\n",
       "      <th>BARTHAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>P12</td>\n",
       "      <td>121.0</td>\n",
       "      <td>92.9</td>\n",
       "      <td>54.9</td>\n",
       "      <td>48.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>...</td>\n",
       "      <td>37.3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>B12</td>\n",
       "      <td>122.5</td>\n",
       "      <td>100.8</td>\n",
       "      <td>55.7</td>\n",
       "      <td>51.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>...</td>\n",
       "      <td>39.5</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>P12</td>\n",
       "      <td>118.3</td>\n",
       "      <td>98.4</td>\n",
       "      <td>55.4</td>\n",
       "      <td>49.7</td>\n",
       "      <td>18.1</td>\n",
       "      <td>...</td>\n",
       "      <td>39.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>BE</td>\n",
       "      <td>127.1</td>\n",
       "      <td>92.7</td>\n",
       "      <td>57.2</td>\n",
       "      <td>44.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>...</td>\n",
       "      <td>36.1</td>\n",
       "      <td>31.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>Duke</td>\n",
       "      <td>ACC</td>\n",
       "      <td>121.8</td>\n",
       "      <td>95.9</td>\n",
       "      <td>55.3</td>\n",
       "      <td>48.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>38.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>WCC</td>\n",
       "      <td>123.0</td>\n",
       "      <td>98.3</td>\n",
       "      <td>57.1</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.1</td>\n",
       "      <td>...</td>\n",
       "      <td>36.3</td>\n",
       "      <td>33.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>186</td>\n",
       "      <td>Houston</td>\n",
       "      <td>B12</td>\n",
       "      <td>120.3</td>\n",
       "      <td>86.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>43.9</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>34.9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>B10</td>\n",
       "      <td>126.9</td>\n",
       "      <td>101.8</td>\n",
       "      <td>54.4</td>\n",
       "      <td>47.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>93</td>\n",
       "      <td>Iowa St.</td>\n",
       "      <td>B12</td>\n",
       "      <td>114.1</td>\n",
       "      <td>87.4</td>\n",
       "      <td>52.2</td>\n",
       "      <td>47.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>...</td>\n",
       "      <td>35.6</td>\n",
       "      <td>31.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>51</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>B12</td>\n",
       "      <td>113.7</td>\n",
       "      <td>94.1</td>\n",
       "      <td>53.5</td>\n",
       "      <td>48.3</td>\n",
       "      <td>16.5</td>\n",
       "      <td>...</td>\n",
       "      <td>33.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>B10</td>\n",
       "      <td>126.8</td>\n",
       "      <td>94.9</td>\n",
       "      <td>56.2</td>\n",
       "      <td>47.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>40.9</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>42</td>\n",
       "      <td>62</td>\n",
       "      <td>92</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>B10</td>\n",
       "      <td>118.6</td>\n",
       "      <td>98.9</td>\n",
       "      <td>52.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>...</td>\n",
       "      <td>34.9</td>\n",
       "      <td>36.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    level_0  index   RK         TEAM CONF  ADJ. EFF. OFF.  ADJ. EFF. DEF.  \\\n",
       "0         1      2   24      Arizona  P12           121.0            92.9   \n",
       "1         3      4   14       Baylor  B12           122.5           100.8   \n",
       "2         6      9   16     Colorado  P12           118.3            98.4   \n",
       "3         8     11    6  Connecticut   BE           127.1            92.7   \n",
       "4        12     15   18         Duke  ACC           121.8            95.9   \n",
       "5        15     19    7      Gonzaga  WCC           123.0            98.3   \n",
       "6        16     22  186      Houston  B12           120.3            86.5   \n",
       "7        17     23   31     Illinois  B10           126.9           101.8   \n",
       "8        18     24   93     Iowa St.  B12           114.1            87.4   \n",
       "9        20     26   51       Kansas  B12           113.7            94.1   \n",
       "10       32     43   12       Purdue  B10           126.8            94.9   \n",
       "11       42     62   92    Wisconsin  B10           118.6            98.9   \n",
       "\n",
       "    EFF. FG% OFF.  EFF. FG% DEF.  TURNOVER% OFF.  ...  3P% OFF.  3P% DEF.  \\\n",
       "0            54.9           48.2            16.1  ...      37.3      33.0   \n",
       "1            55.7           51.4            17.7  ...      39.5      33.4   \n",
       "2            55.4           49.7            18.1  ...      39.1      32.1   \n",
       "3            57.2           44.7            14.7  ...      36.1      31.3   \n",
       "4            55.3           48.7            14.2  ...      38.1      32.1   \n",
       "5            57.1           46.8            14.1  ...      36.3      33.8   \n",
       "6            50.5           43.9            13.7  ...      34.9      30.0   \n",
       "7            54.4           47.9            15.0  ...      35.2      34.3   \n",
       "8            52.2           47.3            15.5  ...      35.6      31.5   \n",
       "9            53.5           48.3            16.5  ...      33.6      34.6   \n",
       "10           56.2           47.3            16.3  ...      40.9      31.4   \n",
       "11           52.2           52.0            14.9  ...      34.9      36.9   \n",
       "\n",
       "    R64  R32  S16  E8  F4  F2  CHAMP  BARTHAG  \n",
       "0     1    1    1   0   0   0      0   0.9546  \n",
       "1     1    1    0   0   0   0      0   0.9046  \n",
       "2     1    1    0   0   0   0      0   0.8861  \n",
       "3     1    1    1   1   1   1      1   0.9686  \n",
       "4     1    1    1   1   0   0      0   0.9265  \n",
       "5     1    1    1   0   0   0      0   0.9132  \n",
       "6     1    1    1   0   0   0      0   0.9778  \n",
       "7     1    1    1   1   0   0      0   0.9187  \n",
       "8     1    1    1   0   0   0      0   0.9520  \n",
       "9     1    1    0   0   0   0      0   0.9078  \n",
       "10    1    1    1   1   1   1      0   0.9659  \n",
       "11    1    0    0   0   0   0      0   0.9006  \n",
       "\n",
       "[12 rows x 29 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new data frame that filters out the losers of the second round so we can just have the winners\n",
    "sweet16_test_dataset = second_round_test_dataset.loc[predicted_winners]\n",
    "# reset the index numbers\n",
    "sweet16_test_dataset = sweet16_test_dataset.reset_index()\n",
    "# set y_train to the column of the actual winners of the sweet 16 of the combined data set\n",
    "y_train = train_dataset['E8']\n",
    "# set y_test to the column of the winners of the sweet 16 of the 2024 data set\n",
    "y_test = sweet16_test_dataset['E8']\n",
    "# set x_test to the winners of the second round, but drop all columns that aren't related to a team's statistics\n",
    "X_test = sweet16_test_dataset.drop([\"RK\",'TEAM',\"CONF\", \"R64\", 'R32', 'S16', 'E8', 'F4','F2','CHAMP', 'index', 'level_0'],axis = 1)\n",
    "sweet16_test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da458f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 4]\n",
      " [0 4]]\n",
      "Accuracy =  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# create a svm classification model\n",
    "model = svm.SVC(kernel = 'rbf',C =100000, gamma = 'scale')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#create a confusion matrix and print overall accuracy score\n",
    "matrix = metrics.confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "print(matrix)\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_true = y_test, y_pred = model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87aec993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Arizona',\n",
       " 'Connecticut',\n",
       " 'Duke',\n",
       " 'Gonzaga',\n",
       " 'Houston',\n",
       " 'Illinois',\n",
       " 'Iowa St.',\n",
       " 'Purdue']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out which teams the model predicted on winning in the sweet 16\n",
    "predicted_winners = []\n",
    "\n",
    "# put the index numbers of the predicted winners into an array\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_pred[i] == 1):\n",
    "        predicted_winners.append(i)\n",
    "        \n",
    "print(len(predicted_winners))\n",
    "\n",
    "\n",
    "predicted_team_winners = []\n",
    "\n",
    "# go through the second round winners and find the names of the next predicted winners by using their index numbers.\n",
    "for i in range(len(sweet16_test_dataset)):\n",
    "    for index in predicted_winners:\n",
    "        if (i == index):\n",
    "            predicted_team_winners.append(sweet16_test_dataset[\"TEAM\"][i])\n",
    "    \n",
    "print(len(predicted_team_winners))\n",
    "predicted_team_winners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a9ea12",
   "metadata": {},
   "source": [
    "#### Elite Eight Winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef44435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>RK</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <th>...</th>\n",
       "      <th>3P% OFF.</th>\n",
       "      <th>3P% DEF.</th>\n",
       "      <th>R64</th>\n",
       "      <th>R32</th>\n",
       "      <th>S16</th>\n",
       "      <th>E8</th>\n",
       "      <th>F4</th>\n",
       "      <th>F2</th>\n",
       "      <th>CHAMP</th>\n",
       "      <th>BARTHAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>P12</td>\n",
       "      <td>121.0</td>\n",
       "      <td>92.9</td>\n",
       "      <td>54.9</td>\n",
       "      <td>48.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>...</td>\n",
       "      <td>37.3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>BE</td>\n",
       "      <td>127.1</td>\n",
       "      <td>92.7</td>\n",
       "      <td>57.2</td>\n",
       "      <td>44.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>...</td>\n",
       "      <td>36.1</td>\n",
       "      <td>31.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>Duke</td>\n",
       "      <td>ACC</td>\n",
       "      <td>121.8</td>\n",
       "      <td>95.9</td>\n",
       "      <td>55.3</td>\n",
       "      <td>48.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>38.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>WCC</td>\n",
       "      <td>123.0</td>\n",
       "      <td>98.3</td>\n",
       "      <td>57.1</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.1</td>\n",
       "      <td>...</td>\n",
       "      <td>36.3</td>\n",
       "      <td>33.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>186</td>\n",
       "      <td>Houston</td>\n",
       "      <td>B12</td>\n",
       "      <td>120.3</td>\n",
       "      <td>86.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>43.9</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>34.9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>B10</td>\n",
       "      <td>126.9</td>\n",
       "      <td>101.8</td>\n",
       "      <td>54.4</td>\n",
       "      <td>47.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>93</td>\n",
       "      <td>Iowa St.</td>\n",
       "      <td>B12</td>\n",
       "      <td>114.1</td>\n",
       "      <td>87.4</td>\n",
       "      <td>52.2</td>\n",
       "      <td>47.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>...</td>\n",
       "      <td>35.6</td>\n",
       "      <td>31.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>B10</td>\n",
       "      <td>126.8</td>\n",
       "      <td>94.9</td>\n",
       "      <td>56.2</td>\n",
       "      <td>47.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>40.9</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index   RK         TEAM CONF  ADJ. EFF. OFF.  ADJ. EFF. DEF.  \\\n",
       "0        1      2   24      Arizona  P12           121.0            92.9   \n",
       "1        8     11    6  Connecticut   BE           127.1            92.7   \n",
       "2       12     15   18         Duke  ACC           121.8            95.9   \n",
       "3       15     19    7      Gonzaga  WCC           123.0            98.3   \n",
       "4       16     22  186      Houston  B12           120.3            86.5   \n",
       "5       17     23   31     Illinois  B10           126.9           101.8   \n",
       "6       18     24   93     Iowa St.  B12           114.1            87.4   \n",
       "7       32     43   12       Purdue  B10           126.8            94.9   \n",
       "\n",
       "   EFF. FG% OFF.  EFF. FG% DEF.  TURNOVER% OFF.  ...  3P% OFF.  3P% DEF.  R64  \\\n",
       "0           54.9           48.2            16.1  ...      37.3      33.0    1   \n",
       "1           57.2           44.7            14.7  ...      36.1      31.3    1   \n",
       "2           55.3           48.7            14.2  ...      38.1      32.1    1   \n",
       "3           57.1           46.8            14.1  ...      36.3      33.8    1   \n",
       "4           50.5           43.9            13.7  ...      34.9      30.0    1   \n",
       "5           54.4           47.9            15.0  ...      35.2      34.3    1   \n",
       "6           52.2           47.3            15.5  ...      35.6      31.5    1   \n",
       "7           56.2           47.3            16.3  ...      40.9      31.4    1   \n",
       "\n",
       "   R32  S16  E8  F4  F2  CHAMP  BARTHAG  \n",
       "0    1    1   0   0   0      0   0.9546  \n",
       "1    1    1   1   1   1      1   0.9686  \n",
       "2    1    1   1   0   0      0   0.9265  \n",
       "3    1    1   0   0   0      0   0.9132  \n",
       "4    1    1   0   0   0      0   0.9778  \n",
       "5    1    1   1   0   0      0   0.9187  \n",
       "6    1    1   0   0   0      0   0.9520  \n",
       "7    1    1   1   1   1      0   0.9659  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new data frame that filters out the losers of the sweet 16 round so we can just have the winners\n",
    "elite8_test_dataset = sweet16_test_dataset.loc[predicted_winners]\n",
    "# reset the index numbers\n",
    "elite8_test_dataset = elite8_test_dataset.reset_index(drop = True)\n",
    "# set y_train to the column of the actual winners of the elite 8 of the combined data set\n",
    "y_train = train_dataset['F4']\n",
    "# set y_test to the column of the winners of the elite 8 of the 2024 data set\n",
    "y_test = elite8_test_dataset['F4']\n",
    "# set x_test to the winners of the sweet 16, but drop all columns that aren't related to a team's statistics\n",
    "X_test = elite8_test_dataset.drop([\"RK\",'TEAM',\"CONF\", \"R64\", 'R32', 'S16', 'E8', 'F4','F2','CHAMP', 'index', 'level_0'],axis = 1)\n",
    "elite8_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa6fc6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0]\n",
      " [0 2]]\n",
      "Accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "# create a svm classification model\n",
    "model = svm.SVC(kernel = 'rbf',C =10000, gamma = 'scale')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#create a confusion matrix and print overall accuracy score\n",
    "matrix = metrics.confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "print(matrix)\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_true = y_test, y_pred = model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cb6b675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Connecticut', 'Purdue']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out which teams the model predicted on winning in the elite 8\n",
    "predicted_winners = []\n",
    "\n",
    "# put the index numbers of the predicted winners into an array\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_pred[i] == 1):\n",
    "        predicted_winners.append(i)\n",
    "        \n",
    "print(len(predicted_winners))\n",
    "\n",
    "\n",
    "predicted_team_winners = []\n",
    "\n",
    "# go through the sweet 16 winners and find the names of the next predicted winners by using their index numbers.\n",
    "for i in range(len(elite8_test_dataset)):\n",
    "    for index in predicted_winners:\n",
    "        if (i == index):\n",
    "            predicted_team_winners.append(elite8_test_dataset[\"TEAM\"][i])\n",
    "    \n",
    "print(len(predicted_team_winners))\n",
    "predicted_team_winners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98177e40",
   "metadata": {},
   "source": [
    "#### Final Four Winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f70235d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>RK</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <th>...</th>\n",
       "      <th>3P% OFF.</th>\n",
       "      <th>3P% DEF.</th>\n",
       "      <th>R64</th>\n",
       "      <th>R32</th>\n",
       "      <th>S16</th>\n",
       "      <th>E8</th>\n",
       "      <th>F4</th>\n",
       "      <th>F2</th>\n",
       "      <th>CHAMP</th>\n",
       "      <th>BARTHAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>BE</td>\n",
       "      <td>127.1</td>\n",
       "      <td>92.7</td>\n",
       "      <td>57.2</td>\n",
       "      <td>44.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>...</td>\n",
       "      <td>36.1</td>\n",
       "      <td>31.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>B10</td>\n",
       "      <td>126.8</td>\n",
       "      <td>94.9</td>\n",
       "      <td>56.2</td>\n",
       "      <td>47.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>40.9</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index  RK         TEAM CONF  ADJ. EFF. OFF.  ADJ. EFF. DEF.  \\\n",
       "0        8     11   6  Connecticut   BE           127.1            92.7   \n",
       "1       32     43  12       Purdue  B10           126.8            94.9   \n",
       "\n",
       "   EFF. FG% OFF.  EFF. FG% DEF.  TURNOVER% OFF.  ...  3P% OFF.  3P% DEF.  R64  \\\n",
       "0           57.2           44.7            14.7  ...      36.1      31.3    1   \n",
       "1           56.2           47.3            16.3  ...      40.9      31.4    1   \n",
       "\n",
       "   R32  S16  E8  F4  F2  CHAMP  BARTHAG  \n",
       "0    1    1   1   1   1      1   0.9686  \n",
       "1    1    1   1   1   1      0   0.9659  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new data frame that filters out the losers of the elite 8 round so we can just have the winners\n",
    "final4_test_dataset = elite8_test_dataset.loc[predicted_winners]\n",
    "# reset the index numbers\n",
    "final4_test_dataset = final4_test_dataset.reset_index(drop = True)\n",
    "# set y_train to the column of the actual winners of the final four of the combined data set\n",
    "y_train = train_dataset['F2']\n",
    "# set y_test to the column of the winners of the final four of the 2024 data set\n",
    "y_test = final4_test_dataset['F2']\n",
    "# set x_test to the winners of the elite eight, but drop all columns that aren't related to a team's statistics\n",
    "X_test = final4_test_dataset.drop([\"RK\",'TEAM',\"CONF\", \"R64\", 'R32', 'S16', 'E8', 'F4','F2','CHAMP', 'index', 'level_0'],axis = 1)\n",
    "final4_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d49cf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]]\n",
      "Accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "# create a svm classification model\n",
    "model = svm.SVC(kernel = 'rbf',C =10000, gamma = 'scale')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#create a confusion matrix and print overall accuracy score\n",
    "matrix = metrics.confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "print(matrix)\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_true = y_test, y_pred = model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff929d7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Connecticut', 'Purdue']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out which teams the model predicted on winning in the final four\n",
    "predicted_winners = []\n",
    "\n",
    "# put the index numbers of the predicted winners into an array\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_pred[i] == 1):\n",
    "        predicted_winners.append(i)\n",
    "        \n",
    "print(len(predicted_winners))\n",
    "\n",
    "\n",
    "predicted_team_winners = []\n",
    "\n",
    "# go through the elite 8 winners and find the names of the next predicted winners by using their index numbers.\n",
    "for i in range(len(final4_test_dataset)):\n",
    "    for index in predicted_winners:\n",
    "        if (i == index):\n",
    "            predicted_team_winners.append(final4_test_dataset[\"TEAM\"][i])\n",
    "    \n",
    "print(len(predicted_team_winners))\n",
    "predicted_team_winners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5063230",
   "metadata": {},
   "source": [
    "#### Championship Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b87e2c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>RK</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <th>...</th>\n",
       "      <th>3P% OFF.</th>\n",
       "      <th>3P% DEF.</th>\n",
       "      <th>R64</th>\n",
       "      <th>R32</th>\n",
       "      <th>S16</th>\n",
       "      <th>E8</th>\n",
       "      <th>F4</th>\n",
       "      <th>F2</th>\n",
       "      <th>CHAMP</th>\n",
       "      <th>BARTHAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>BE</td>\n",
       "      <td>127.1</td>\n",
       "      <td>92.7</td>\n",
       "      <td>57.2</td>\n",
       "      <td>44.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>...</td>\n",
       "      <td>36.1</td>\n",
       "      <td>31.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>B10</td>\n",
       "      <td>126.8</td>\n",
       "      <td>94.9</td>\n",
       "      <td>56.2</td>\n",
       "      <td>47.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>40.9</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index  RK         TEAM CONF  ADJ. EFF. OFF.  ADJ. EFF. DEF.  \\\n",
       "0        8     11   6  Connecticut   BE           127.1            92.7   \n",
       "1       32     43  12       Purdue  B10           126.8            94.9   \n",
       "\n",
       "   EFF. FG% OFF.  EFF. FG% DEF.  TURNOVER% OFF.  ...  3P% OFF.  3P% DEF.  R64  \\\n",
       "0           57.2           44.7            14.7  ...      36.1      31.3    1   \n",
       "1           56.2           47.3            16.3  ...      40.9      31.4    1   \n",
       "\n",
       "   R32  S16  E8  F4  F2  CHAMP  BARTHAG  \n",
       "0    1    1   1   1   1      1   0.9686  \n",
       "1    1    1   1   1   1      0   0.9659  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new data frame that filters out the losers of the final four so we can just have the winners\n",
    "champ_test_dataset = final4_test_dataset.loc[predicted_winners]\n",
    "# reset the index numbers\n",
    "champ_test_dataset = champ_test_dataset.reset_index(drop = True)\n",
    "# set y_train to the column of the actual winner of the championship of the combined data set\n",
    "y_train = train_dataset['CHAMP']\n",
    "# set y_test to the column of the winner of the championship of the 2024 data set\n",
    "y_test = champ_test_dataset['CHAMP']\n",
    "# set x_test to the winners of the final four, but drop all columns that aren't related to a team's statistics\n",
    "X_test = champ_test_dataset.drop([\"RK\",'TEAM',\"CONF\", \"R64\", 'R32', 'S16', 'E8', 'F4','F2','CHAMP', 'index', 'level_0'],axis = 1)\n",
    "champ_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bab3fdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [1 0]]\n",
      "Accuracy =  0.0\n"
     ]
    }
   ],
   "source": [
    "# create a svm classification model\n",
    "model = svm.SVC(kernel = 'rbf',C =1000, gamma = 'scale')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#create a confusion matrix and print overall accuracy score\n",
    "matrix = metrics.confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "print(matrix)\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_true = y_test, y_pred = model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1d5c1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "['Purdue']\n"
     ]
    }
   ],
   "source": [
    "# find out which teams the model predicted on winning in the championship\n",
    "predicted_winner = []\n",
    "\n",
    "# put the index numbers of the predicted winner into an array\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_pred[i] == 1):\n",
    "        predicted_winner.append(i)\n",
    "        \n",
    "print(len(predicted_winner))\n",
    "\n",
    "\n",
    "predicted_team_winner = []\n",
    "\n",
    "# go through the final four winners and find the name of the next predicted winner by using their index number.\n",
    "for i in range(len(champ_test_dataset)):\n",
    "    for index in predicted_winner:\n",
    "        if (i == index):\n",
    "            predicted_team_winner.append(champ_test_dataset[\"TEAM\"][i])\n",
    "    \n",
    "print(len(predicted_team_winner))\n",
    "print(predicted_team_winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de36ac",
   "metadata": {},
   "source": [
    "### KNN exploratory analysis - Using KNN On 2024 Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a04cc4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the 2024 data \n",
    "data_2024 = pd.read_csv('2024 Final Total Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a01de",
   "metadata": {},
   "source": [
    "#### KNN Second Round Prediction On 2024 Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee20b09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 68.75 %\n"
     ]
    }
   ],
   "source": [
    "# drop non-numeric values and things we use to predict \n",
    "XTrain = data.drop(columns = ['RK','TEAM','CONF', 'R64','R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP'], axis = 1)\n",
    "XTest = data_2024.drop(columns = ['RK','TEAM','CONF', 'R64','R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP'], axis = 1)\n",
    "yTrain = data['R32'] # the training data will be the combined data (from 2009, 2016, 2017)\n",
    "yTest = data_2024['R32'] #the testing data will be the 2024 data \n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 1) # define the model \n",
    "model.fit(XTrain, yTrain) #apply the model to the training data \n",
    "y_pred = model.predict(XTest) #make predictions \n",
    "\n",
    "print('Accuracy on test data = {:.2f}'.format(metrics.accuracy_score(y_true = yTest, y_pred = y_pred)*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c92e606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_winners = []\n",
    "for i in range(len(y_pred)): # loop through the length of the predicted variable \n",
    "    if y_pred[i] == 1: # if the value of the predicted variable is 1, put it into the array `predicted_winners`\n",
    "        predicted_winners.append(i) #  put it into the array `predicted_winners`\n",
    "\n",
    "predicted_teams = []\n",
    "\n",
    "for j in range(len(data_2024)): # loop through the length of the 2024 data \n",
    "    for i in predicted_winners: # go through the predicted winners array that we created above \n",
    "        if j == i: # when the team in the 2024 data is also in the predicted winners from our model, \n",
    "            predicted_teams.append(data_2024['TEAM'][j]) # append the team name to the new list \n",
    "\n",
    "\n",
    "actual_winners = [] # essentially doing the same this as above just with the teams that actually won so that we can compare\n",
    "\n",
    "for i in range(len(yTest)): \n",
    "    if yTest[i] == 1: \n",
    "        actual_winners.append(i)\n",
    "        \n",
    "actual_teams = [] \n",
    "for j in range(len(data_2024)): \n",
    "    for i in actual_winners: \n",
    "        if j == i: \n",
    "            actual_teams.append(data_2024['TEAM'][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0e36128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams that were predicted:\n",
      " ['Alabama', 'Auburn', 'Baylor', 'BYU', 'Clemson', 'Colorado', 'Connecticut', 'Creighton', 'Dayton', 'Duke', 'Duquesne', 'Florida', 'Florida Atlantic', 'Gonzaga', 'Houston', 'Illinois', 'Iowa St.', 'James Madison', 'Marquette', 'Michigan St.', 'Nebraska', 'New Mexico', 'Northwestern', 'Oakland', \"Saint Mary's\", 'San Diego St.', 'TCU', 'Tennessee', 'Texas', 'Texas Tech', 'Utah St.', 'Wisconsin']\n",
      "\n",
      "Teams that actually made it:\n",
      " ['Alabama', 'Arizona', 'Baylor', 'Clemson', 'Colorado', 'Connecticut', 'Creighton', 'Dayton', 'Duke', 'Duquesne', 'Gonzaga', 'Grand Canyon', 'Houston', 'Illinois', 'Iowa St.', 'James Madison', 'Kansas', 'Marquette', 'Michigan St.', 'North Carolina', 'North Carolina St.', 'Northwestern', 'Oakland', 'Oregon', 'Purdue', 'San Diego St.', 'Tennessee', 'Texas', 'Texas A&M', 'Utah St.', 'Washington St.', 'Yale']\n",
      "\n",
      "check to see how many teams it predicted: 32\n",
      "\n",
      "how many teams there actually are: 32\n"
     ]
    }
   ],
   "source": [
    "print('Teams that were predicted:\\n' , predicted_teams)\n",
    "print()\n",
    "print('Teams that actually made it:\\n', actual_teams)\n",
    "print()\n",
    "print('check to see how many teams it predicted:', len(predicted_teams))\n",
    "print() \n",
    "print('how many teams there actually are:', len(actual_teams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec63ee4",
   "metadata": {},
   "source": [
    "#### KNN Sweet 16 Prediction On 2024 Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "feca0809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 62.50 %\n"
     ]
    }
   ],
   "source": [
    "sweet16 = data_2024.loc[predicted_winners] # edit the data so that the sweet 16 data only contains the winners our model predcited for the second round \n",
    "sweet16 = sweet16.reset_index() # have to reset the index so that we can find the index of our variables \n",
    "y_Train = data['S16'] # want to train from the ORIGINAL COMBINED DATA SET \n",
    "y_Test = sweet16['S16'] # want to test only on the 2024 data \n",
    "X_Test = sweet16.drop(columns = ['RK','TEAM','CONF', 'R64','R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'index'], axis = 1)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 1) # create the model with 1 neighbor \n",
    "model.fit(XTrain, y_Train) # apply the model to the training data \n",
    "y_pred = model.predict(X_Test) #predict the winners \n",
    "\n",
    "print('Accuracy on test data = {:.2f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred)*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ccc7029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teams that were predicted:\n",
      " ['Auburn', 'Clemson', 'Colorado', 'Connecticut', 'Duke', 'Florida Atlantic', 'Gonzaga', 'Illinois', 'Iowa St.', 'Nebraska', 'Northwestern', 'Tennessee', 'Texas Tech', 'Wisconsin']\n"
     ]
    }
   ],
   "source": [
    "predicted_winners = []\n",
    "for i in range(len(y_pred)): # loop through the length of the predicted variable \n",
    "    if y_pred[i] == 1: # if the value of the predicted variable is 1, put it into the array `predicted_winners`\n",
    "        predicted_winners.append(i)\n",
    "\n",
    "predicted_teams = []\n",
    "\n",
    "for j in range(len(sweet16)): # loop through the length of the sweet 16 data \n",
    "    for i in predicted_winners: \n",
    "        if j == i: # when the team in the sweet 16 data is also in the predicted winners from our model, \n",
    "            predicted_teams.append(sweet16['TEAM'][j])\n",
    "            \n",
    "print('teams that were predicted:\\n', list(predicted_teams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4148e23e",
   "metadata": {},
   "source": [
    "#### KNN Elite 8 Prediction On 2024 Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19a057de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 64.29 %\n"
     ]
    }
   ],
   "source": [
    "elite8 = sweet16.loc[predicted_winners] # edit the data such that it only contains the winners that our model precited in sweet 16\n",
    "elite8 = elite8.reset_index() #have to reset the index of our dataset \n",
    "y_Train = data['E8'] # train off of the ORIGINAL DATA SET OF COMBINED YEARS \n",
    "y_Test = elite8['E8'] # predict from the 2024 data \n",
    "X_Test = elite8.drop(columns = ['RK','TEAM','CONF', 'R64','R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'index', 'level_0'], axis = 1)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 1) #define the model \n",
    "model.fit(XTrain, y_Train) #apply the model \n",
    "y_pred = model.predict(X_Test) # predict \n",
    "\n",
    "print('Accuracy on test data = {:.2f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred)*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bb91054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[5 4]\n",
      " [1 4]]\n",
      "\n",
      "teams that were predicted:\n",
      " ['Auburn', 'Connecticut', 'Duke', 'Florida Atlantic', 'Gonzaga', 'Illinois', 'Iowa St.', 'Tennessee']\n"
     ]
    }
   ],
   "source": [
    "predicted_winners = []\n",
    "for i in range(len(y_pred)):# loop through the length of the predicted variable \n",
    "    if y_pred[i] == 1: # if the value of the predicted variable is 1, put it into the array `predicted_winners`\n",
    "        predicted_winners.append(i)\n",
    "        \n",
    "len(predicted_winners)\n",
    "\n",
    "predicted_teams = []\n",
    "\n",
    "for j in range(len(elite8)): # loop through the length of the elite 8 data \n",
    "    for i in predicted_winners: \n",
    "        if j == i: # when the team in the elite 8 data is also in the predicted winners from our model, \n",
    "            predicted_teams.append(elite8['TEAM'][j]) # return the team names \n",
    "            \n",
    "            \n",
    "print('confusion matrix: \\n', metrics.confusion_matrix(y_Test, y_pred))  \n",
    "print()\n",
    "print('teams that were predicted:\\n', predicted_teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c632481",
   "metadata": {},
   "source": [
    "#### KNN Final Four Prediction On 2024 Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "485749e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 75.00 %\n"
     ]
    }
   ],
   "source": [
    "finalfour = elite8.loc[predicted_winners] # create a new dataset that only contains the winners of the elite 8 round that our model predicted \n",
    "finalfour = finalfour.reset_index(drop = True) \n",
    "y_Train = data['F4'] # train off of the ORIGINAL DATA SET OF COMBINED YEARS \n",
    "y_Test = finalfour['F4'] # test from the 2024 dataset \n",
    "X_Test = finalfour.drop(columns = ['RK','TEAM','CONF', 'R64','R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'index', 'level_0'], axis = 1)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 1) # create the model and decide number of neighbors \n",
    "model.fit(XTrain, y_Train) # apply the model to the training data \n",
    "y_pred = model.predict(X_Test) # predict based off the 2024 data \n",
    "\n",
    "print('Accuracy on test data = {:.2f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred)*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d1774b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[5 2]\n",
      " [0 1]]\n",
      "\n",
      "teams that were predicted:\n",
      " ['Connecticut', 'Duke', 'Gonzaga']\n"
     ]
    }
   ],
   "source": [
    "predicted_winners = []\n",
    "for i in range(len(y_pred)): # loop through the length of the predicted variable \n",
    "    if y_pred[i] == 1:  # if the value of the predicted variable is 1, put it into the array `predicted_winners`\n",
    "        predicted_winners.append(i)\n",
    "        \n",
    "len(predicted_winners)\n",
    "\n",
    "predicted_teams = []\n",
    "\n",
    "for j in range(len(finalfour)): # loop through the length of the final 4 data\n",
    "    for i in predicted_winners: \n",
    "        if j == i: # when the team in the final 4 data is also in the predicted winners from our model,\n",
    "            predicted_teams.append(finalfour['TEAM'][j]) # return the team names \n",
    "            \n",
    "            \n",
    "print('confusion matrix: \\n', metrics.confusion_matrix(y_Test, y_pred))  \n",
    "print()\n",
    "print('teams that were predicted:\\n', predicted_teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e176baed",
   "metadata": {},
   "source": [
    "#### KNN Final 2 Prediction On 2024 Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b767805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 100.00 %\n"
     ]
    }
   ],
   "source": [
    "finaltwo = finalfour.loc[predicted_winners] # create a new dataset such that the only data in it are the predicted winners from the final 4 \n",
    "finaltwo = finaltwo.reset_index(drop = True) # reset the index of the dataset \n",
    "y_Train = data['F2'] # train based off of the ORIGINAL DATA OF THE PREVIOUS YEARS \n",
    "y_Test = finaltwo['F2'] # test based on the 2024 data \n",
    "X_Test = finaltwo.drop(columns = ['RK','TEAM','CONF', 'R64','R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'index', 'level_0'], axis = 1)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 1) # define the model \n",
    "model.fit(XTrain, y_Train) # apply the model to the training data \n",
    "y_pred = model.predict(X_Test) # predict \n",
    "\n",
    "print('Accuracy on test data = {:.2f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred)*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ee30659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[2 0]\n",
      " [0 1]]\n",
      "\n",
      "teams that were predicted:\n",
      " ['Connecticut']\n"
     ]
    }
   ],
   "source": [
    "predicted_winners = []\n",
    "for i in range(len(y_pred)): # loop through the length of the predicted variable \n",
    "    if y_pred[i] == 1: # if the value of the predicted variable is 1, put it into the array `predicted_winners`\n",
    "        predicted_winners.append(i)\n",
    "        \n",
    "len(predicted_winners)\n",
    "\n",
    "predicted_teams = []\n",
    "\n",
    "for j in range(len(finaltwo)): # loop through the length of the final 2 data\n",
    "    for i in predicted_winners: \n",
    "        if j == i:  # when the team in the final 2 data is also in the predicted winners from our model,\n",
    "            predicted_teams.append(finaltwo['TEAM'][j]) # return the team names \n",
    "            \n",
    "            \n",
    "print('confusion matrix: \\n', metrics.confusion_matrix(y_Test, y_pred))  \n",
    "print()\n",
    "print('teams that were predicted:\\n', predicted_teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f80bd",
   "metadata": {},
   "source": [
    "#### KNN Champtionship Prediction On 2024 Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1fe4f468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 0.00 %\n"
     ]
    }
   ],
   "source": [
    "champ = finaltwo.loc[predicted_winners] # subset the data such that only the winners from the final two are in the dataset \n",
    "champ = champ.reset_index(drop = True) # reset the index \n",
    "y_Train = data['CHAMP'] # train off of the ORIGINAL COMBINED DATA \n",
    "y_Test = champ['CHAMP'] # test on the 2024 data \n",
    "X_Test = champ.drop(columns = ['RK','TEAM','CONF', 'R64','R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'index', 'level_0'], axis = 1)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 1) # create the model \n",
    "model.fit(XTrain, y_Train) # apply the model to the training data \n",
    "y_pred = model.predict(X_Test) # test on the 2024 data\n",
    "\n",
    "print('Accuracy on test data = {:.2f}'.format(metrics.accuracy_score(y_true = y_Test, y_pred = y_pred)*100), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83da3be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[0 0]\n",
      " [1 0]]\n",
      "\n",
      "teams that were predicted:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "predicted_winners = []\n",
    "for i in range(len(y_pred)): # loop through the length of the predicted variable \n",
    "    if y_pred[i] == 1: # if the value of the predicted variable is 1, put it into the array `predicted_winners`\n",
    "        predicted_winners.append(i)\n",
    "        \n",
    "len(predicted_winners)\n",
    "\n",
    "predicted_teams = []\n",
    "\n",
    "for j in range(len(champ)): # loop through the length of the champ data\n",
    "    for i in predicted_winners: \n",
    "        if j == i: # when the team in the champ data is also in the predicted winners from our model,\n",
    "            predicted_teams.append(champ['TEAM'][j])# return the team names \n",
    "            \n",
    "            \n",
    "print('confusion matrix: \\n', metrics.confusion_matrix(y_Test, y_pred))  \n",
    "print()\n",
    "print('teams that were predicted:\\n', predicted_teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52e782",
   "metadata": {},
   "source": [
    "Through the application of KNN on the 2024 data, the only thing that was varied to increase accuracy was the number of neighbors. For each of these, we opted to use a value of k = 1, because it provided the highest accuracy. \n",
    "\n",
    "Having a single neighbor means that the data has low bias, and it is trying to capture all of the intricacies and nuances of the training data. It is common to see that in a KNN model, the data will be 'overfit' with a k value of 1, but since the model did not return an obscenely high accuracy from the beginning, we determined that k = 1 was appropriate, as it did not appear that it was overfitting too much. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c80173",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304501c",
   "metadata": {},
   "source": [
    "Explain the accuracy of each round and the teams the survived the longest and how that compares to the actual tournament bracket. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cffd38b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b4b750",
   "metadata": {},
   "source": [
    "Throughout our process, we found that scaling the data did not help increase the accuracy of the models we were using. In some instances it appeared like it might, but then we realized that there was high probability that this was leading to overfitting of the data. \n",
    "\n",
    "Given the expansiveness of our dataset, featuring numerous variables, it became apparent that many classification models perform well on these kinds of datasets. We were able to conclude that the decision tree did not perform well, as it gave the lowest accuracy and had large issues with over-fitting the data. \n",
    "\n",
    "To refine our approach, we optimized the SVM's **C** parameter and adjusted the **K** value for the KNN model, which allowed us to fina a balance between maximizing accuracy and mitigating overfitting. \n",
    "\n",
    "A notable challenge that we encountered when designing our model was that our model frequently designated both teams as advancing to the subsequent round, which was a logical inconsistency we were unable to rectify within the framework of our model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d1ef1",
   "metadata": {},
   "source": [
    "## Ethical Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b13256b",
   "metadata": {},
   "source": [
    "**Our ethical considerations include**\n",
    "\n",
    "**1. Impact on the sport itself** \n",
    "    \n",
    "Sports serve as a source of entertainment, and for many athletes, they constitute a livelihood. Implementing a data processing method like this can potentially overshadow the individual achievements of players, reducing their hardwork and effort to mere statistics. This approach risks undermining the recognition of althletes' dedication to their sport and accomplishments. \n",
    "    \n",
    "   \n",
    "**2. Inaccessibility to technology** \n",
    "\n",
    "We must acknowledge that not all March Madness fans have access to technology. This limitation hampers their ability to utilize predicive models in making informed decisions when crafting their brackets, which can in turn create disparities in participation and engagement. \n",
    "\n",
    "\n",
    "**3. Bracket Competitions**\n",
    "\n",
    "\n",
    "The use of predictive models in bracket competitions raises ethical concerns if participants are unaware of its use. This becomes particularly problematic in scenarios involving monetary stakes, where transparency regarding the methodology employed in the creation of one's bracket is essential for fairness and integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a5f79",
   "metadata": {},
   "source": [
    "# Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc65dfdb",
   "metadata": {},
   "source": [
    "In summary, we started by coming up with a topic we were all interested in. We all enjoy the march madness tournament and were excited to put our data science skills to the test on predicting winners in the tournament. Next, we looked for basketball stats that we could use in our model. Once we had data, we cleaned it so we could look at descriptive statistics and make sure the data was clean and accurate. We needed to do some work to get the data in the format we needed to have training and testing data. Finally, we ran KNN, SVM, decision tree, and logistic regression models to see which predicted the winners the best. It appears that logistic regression, KNN, and SVM all perform similarly but for us SVM performed the best. We were able to predict â€¦â€¦â€¦FINISH THIS PART"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
