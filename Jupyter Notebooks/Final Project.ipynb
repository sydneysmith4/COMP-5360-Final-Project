{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d26a57",
   "metadata": {},
   "source": [
    "# Final Project - Predicting March Madness Tournament Winner "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c32c00",
   "metadata": {},
   "source": [
    "**Names:** Lauren Cutler, Hayden Kash, Sydney Smith\n",
    "\n",
    "**Date:** April 19, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8bceba",
   "metadata": {},
   "source": [
    "## Background and Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f33ec5",
   "metadata": {},
   "source": [
    "The reason we chose this project is because of our interest in the March Madness Tournament. We all enjoy watching the tournament every year as it is very exciting to see which college teams in the country will come out on top and be claimed as the best college basketball team. Many people every year always try to predict how the tournament will play out, so we thought why not try to actually do it by using data science. Since the NCAA is always maintaining a substantial amount of statistics on the players and teams, we thought this project would be doable as most of the data is public. Another deciding factor for choosing this project is when we present this project, the tournament will have concluded and we will be able to compare our results to who actually won."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e8d34",
   "metadata": {},
   "source": [
    "## Project Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57882753",
   "metadata": {},
   "source": [
    "The main objective is to look at multiple machine learning models to see which model performs the best in predicting the winners that advance from the round of 64 to the round of 32 and from the round of 32 to the sweet 16. In addition, we will see which model predicts the most correct teams in each round. For example, the model may predict 32 teams to advance from the round of 64 to the round of 32 but not all the 32 predicted teams will be correct. Even if not all the teams are correct if a portion of the teams continue to be correct in each of the rounds of the tournament that will help improve our bracket predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46666c34",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3005306",
   "metadata": {},
   "source": [
    "For our project, we decided to use three data domains to help predict winners in multiple rounds of the 2024 NCAA menâ€™s March Madness basketball tournament. The categories that we determined were the most essential for this project were the March Madness tournament data, the team statistics, and a power rating. Along with 2024 data we also decided to look at previous basketball seasons, to train our prediction model. The previous seasons we selected were the  2017, 2016, and 2009 seasons. The process of selecting these years was by randomly generating 3 random years between 2008-2023, as the website that holds all of the data we need only has the seasons 2008-present. Each dataset we use is in the form of a large data table on https://barttorvik.com/trank.php#, so all we needed to do was paste the data into an Excel file and convert it to a csv file. Therefore, all of the data we read for our project will be only through csv files.\n",
    "\n",
    "We started with three individual data domains for each of the four years. The tournament data contained the winners of each round of the tournament. These columns are our outcomes to predict. The teams data contained data on offensive and defensive efficiencies and turnovers. In total there were 16 statistics for team performance. The barthag column is based off of points per possession and is supposed to calculate the chance of beating a division 1 team. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d8892b",
   "metadata": {},
   "source": [
    "#### Team stats, Barthag, Tournament statistics descriptions\n",
    "\n",
    "**Breakdown of what each metric means:** \n",
    "\n",
    "- **RK** : Team Rank \n",
    "- **CONF** : Conference\n",
    "- **ADJ. EFF. OFF.** : Adjusted Offensive Efficiency \n",
    "- **ADJ. EFF. DEF.** : Adjusted Defensive Efficiency\n",
    "- **EFF. FG% OFF.** :  Effective Field Goal Percentage Offense \n",
    "- **EFF. FG% DEF.** : Effective Field Goal Percentange Deffense\n",
    "- **TURNOVER% OFF.** : Turnover Percentage Offense\n",
    "- **TURNOVER% DEF.** : Turnover Percentage Defense \n",
    "- **REB% OFF.** : Rebound Percentage Offense \n",
    "- **REB% DEF.** : Rebound Percentange Defense \n",
    "- **FT RATE OFF.** : Free Throw Rate Offense \n",
    "- **FT RATE DEF.** : Free Throw Rate Defense \n",
    "- **FT% OFF.** : Free Throw Percentage Offense \n",
    "- **FT% DEF.** : Free Throw Percentage Defense \n",
    "- **2P% OFF.** : 2 Pointer Percentage Offense\n",
    "- **2P% DEF.** : 2 Pointer Percentage Defense \n",
    "- **3P% OFF.** : 3 Pointer Percentage Offense\n",
    "- **3P% DEF.** : 3 Pointer Percentage Defense\n",
    "- **Barthag.** : Power rating (chance of beating a D1 team)\n",
    "- **PAKE** : Performance against Komputer expectations \n",
    "- **PASE** : Performance against seed expectations \n",
    "- **WINS** : Wins excluding play in games \n",
    "- **LOSS** : Losses excluding play in games\n",
    "- **W%** : Win percentage excluding play in games \n",
    "- **R64** : Appearances in the round of 64\n",
    "- **R32** : Appearances in the round of 32\n",
    "- **S16** : Appearances in the sweet 16\n",
    "- **E8** : Appearances in the elite eight\n",
    "- **F4** : Appearances in the final four\n",
    "- **F2** : Championship game appearances\n",
    "- **CHAMP** : National titles\n",
    "- **TOP2** : Years awarded a 1 or 2 seed\n",
    "- **F4%** : Likelihood of getting to at least the final 4\n",
    "- **CHAMP%** : Likelihood of winning at least 1 title per efficiency rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a66288",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf232b",
   "metadata": {},
   "source": [
    "We had to clean the teams data the most. Every other row in the teams data was a rating of that statistic. We did not want these rows in our data. Once we loaded the teams data into a pandas data frame we programmatically removed every other row. We also started with more than the 64 teams in the tournament. We reduced the teams data to the 64 teams for each year. When we tried to reduce the teams to 64 we realized that some of the team names had numbers or rankings in their names. We had to get rid of the rankings in the team names to programmatically get the list to 64. For the tournament and power rating data all we had to do was copy and paste the data from the website into excel and read in the csv file. The tournament and power rating was reduced to the 64 tournament on the website. \n",
    "\n",
    "Once we had 64 teams for each dataset for each year we worked on combining the datasets together. We combine all of previous years into one csv file in excel. This became our training data and what we first used to explore different machine learning models. Then we combine the three datasets for 2024 into one csv file. For all the data we checked to make sure the descriptive statistcs made sense, no dupilicates, and no null values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d51fd31",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5a499",
   "metadata": {},
   "source": [
    "For our exploratory analysis we started by looking at different machine learning models on the 2009, 2016, 2017 data. We looked at logistic regression, decision tree, SVM, KNN. We found that the decision tree did not perform as good as the other three models. Next, we looked at KNN, regression, SVM with the previous years as our training data and 2024 data as our test. All three models had similar accuracy so we moved forward with SVM and KNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "90629b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "\n",
    "import scipy as sc\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm # For regression analysis\n",
    "from sklearn import linear_model # For regression analysis\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92beef",
   "metadata": {},
   "source": [
    "### Logistic Regression exploratory analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a70547f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2009, 2016, 2017 data\n",
    "data = pd.read_excel('Complete Combined Files .xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "34b26c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RK</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <th>TURNOVER% DEF.</th>\n",
       "      <th>OFF. REB% OFF.</th>\n",
       "      <th>...</th>\n",
       "      <th>3P% OFF.</th>\n",
       "      <th>3P% DEF.</th>\n",
       "      <th>R64</th>\n",
       "      <th>R32</th>\n",
       "      <th>S16</th>\n",
       "      <th>E8</th>\n",
       "      <th>F4</th>\n",
       "      <th>F2</th>\n",
       "      <th>CHAMP</th>\n",
       "      <th>BARTHAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206</td>\n",
       "      <td>Akron</td>\n",
       "      <td>MAC</td>\n",
       "      <td>102.9</td>\n",
       "      <td>95.6</td>\n",
       "      <td>48.1</td>\n",
       "      <td>45.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>26.4</td>\n",
       "      <td>34.3</td>\n",
       "      <td>...</td>\n",
       "      <td>33.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>American</td>\n",
       "      <td>Pat</td>\n",
       "      <td>104.2</td>\n",
       "      <td>99.9</td>\n",
       "      <td>53.7</td>\n",
       "      <td>45.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>31.5</td>\n",
       "      <td>...</td>\n",
       "      <td>37.4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>P10</td>\n",
       "      <td>118.4</td>\n",
       "      <td>101.7</td>\n",
       "      <td>53.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>18.4</td>\n",
       "      <td>35.9</td>\n",
       "      <td>...</td>\n",
       "      <td>38.7</td>\n",
       "      <td>34.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Arizona St.</td>\n",
       "      <td>P10</td>\n",
       "      <td>118.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>56.4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>29.1</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>Binghamton</td>\n",
       "      <td>AE</td>\n",
       "      <td>101.6</td>\n",
       "      <td>102.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>46.6</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.6</td>\n",
       "      <td>31.7</td>\n",
       "      <td>...</td>\n",
       "      <td>33.5</td>\n",
       "      <td>32.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RK         TEAM CONF  ADJ. EFF. OFF.  ADJ. EFF. DEF.  EFF. FG% OFF.  \\\n",
       "0  206        Akron  MAC           102.9            95.6           48.1   \n",
       "1   25     American  Pat           104.2            99.9           53.7   \n",
       "2   39      Arizona  P10           118.4           101.7           53.0   \n",
       "3    2  Arizona St.  P10           118.0            94.6           56.4   \n",
       "4  155   Binghamton   AE           101.6           102.3           49.4   \n",
       "\n",
       "   EFF. FG% DEF.  TURNOVER% OFF.  TURNOVER% DEF.  OFF. REB% OFF.  ...  \\\n",
       "0           45.5            20.7            26.4            34.3  ...   \n",
       "1           45.2            21.2            20.8            31.5  ...   \n",
       "2           51.0            19.4            18.4            35.9  ...   \n",
       "3           47.0            18.6            19.5            29.1  ...   \n",
       "4           46.6            19.7            21.6            31.7  ...   \n",
       "\n",
       "   3P% OFF.  3P% DEF.  R64  R32  S16  E8  F4  F2  CHAMP  BARTHAG  \n",
       "0      33.2      29.4    1    0    0   0   0   0      0   0.6871  \n",
       "1      37.4      33.0    1    0    0   0   0   0      0   0.4110  \n",
       "2      38.7      34.9    1    1    1   0   0   0      0   0.6002  \n",
       "3      37.0      31.9    1    1    0   0   0   0      0   0.8540  \n",
       "4      33.5      32.9    1    0    0   0   0   0      0   0.9377  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3ea6174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.drop(['RK','TEAM','CONF', 'R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'R64'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8f2b81d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <th>TURNOVER% DEF.</th>\n",
       "      <th>OFF. REB% OFF.</th>\n",
       "      <th>OFF. REB% DEF.</th>\n",
       "      <th>FT RATE OFF.</th>\n",
       "      <th>FT RATE DEF.</th>\n",
       "      <th>FT% OFF.</th>\n",
       "      <th>FT% DEF.</th>\n",
       "      <th>2P% OFF.</th>\n",
       "      <th>2P% DEF.</th>\n",
       "      <th>3P% OFF.</th>\n",
       "      <th>3P% DEF.</th>\n",
       "      <th>BARTHAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ. EFF. OFF.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302666</td>\n",
       "      <td>0.628170</td>\n",
       "      <td>0.016115</td>\n",
       "      <td>-0.479529</td>\n",
       "      <td>-0.240984</td>\n",
       "      <td>0.161306</td>\n",
       "      <td>-0.136001</td>\n",
       "      <td>-0.102214</td>\n",
       "      <td>-0.286381</td>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.084193</td>\n",
       "      <td>0.529949</td>\n",
       "      <td>-0.034671</td>\n",
       "      <td>0.504958</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.517020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ. EFF. DEF.</th>\n",
       "      <td>-0.302666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030741</td>\n",
       "      <td>0.710293</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>-0.288723</td>\n",
       "      <td>-0.268007</td>\n",
       "      <td>0.086525</td>\n",
       "      <td>0.039824</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>0.156899</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>0.640749</td>\n",
       "      <td>0.046652</td>\n",
       "      <td>0.389342</td>\n",
       "      <td>-0.519868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFF. FG% OFF.</th>\n",
       "      <td>0.628170</td>\n",
       "      <td>0.030741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111205</td>\n",
       "      <td>-0.202413</td>\n",
       "      <td>-0.321216</td>\n",
       "      <td>-0.284749</td>\n",
       "      <td>-0.281031</td>\n",
       "      <td>-0.216726</td>\n",
       "      <td>-0.356844</td>\n",
       "      <td>0.345656</td>\n",
       "      <td>0.067115</td>\n",
       "      <td>0.867997</td>\n",
       "      <td>0.041823</td>\n",
       "      <td>0.747324</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.260174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFF. FG% DEF.</th>\n",
       "      <td>0.016115</td>\n",
       "      <td>0.710293</td>\n",
       "      <td>0.111205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.124246</td>\n",
       "      <td>-0.022969</td>\n",
       "      <td>-0.228701</td>\n",
       "      <td>0.075509</td>\n",
       "      <td>-0.016649</td>\n",
       "      <td>-0.035310</td>\n",
       "      <td>0.146895</td>\n",
       "      <td>0.117667</td>\n",
       "      <td>0.079702</td>\n",
       "      <td>0.882149</td>\n",
       "      <td>0.090346</td>\n",
       "      <td>0.575494</td>\n",
       "      <td>-0.279983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TURNOVER% OFF.</th>\n",
       "      <td>-0.479529</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>-0.202413</td>\n",
       "      <td>-0.124246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215373</td>\n",
       "      <td>0.347886</td>\n",
       "      <td>0.262208</td>\n",
       "      <td>0.295497</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>-0.294047</td>\n",
       "      <td>-0.126160</td>\n",
       "      <td>-0.152853</td>\n",
       "      <td>-0.148887</td>\n",
       "      <td>-0.177384</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>-0.137656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TURNOVER% DEF.</th>\n",
       "      <td>-0.240984</td>\n",
       "      <td>-0.288723</td>\n",
       "      <td>-0.321216</td>\n",
       "      <td>-0.022969</td>\n",
       "      <td>0.215373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192090</td>\n",
       "      <td>0.489894</td>\n",
       "      <td>-0.031002</td>\n",
       "      <td>0.440002</td>\n",
       "      <td>-0.220110</td>\n",
       "      <td>-0.207003</td>\n",
       "      <td>-0.237096</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>-0.294161</td>\n",
       "      <td>-0.111957</td>\n",
       "      <td>-0.041799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFF. REB% OFF.</th>\n",
       "      <td>0.161306</td>\n",
       "      <td>-0.268007</td>\n",
       "      <td>-0.284749</td>\n",
       "      <td>-0.228701</td>\n",
       "      <td>0.347886</td>\n",
       "      <td>0.192090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162419</td>\n",
       "      <td>0.254524</td>\n",
       "      <td>0.174179</td>\n",
       "      <td>-0.229168</td>\n",
       "      <td>-0.093387</td>\n",
       "      <td>-0.190445</td>\n",
       "      <td>-0.229249</td>\n",
       "      <td>-0.245206</td>\n",
       "      <td>-0.081738</td>\n",
       "      <td>0.154509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFF. REB% DEF.</th>\n",
       "      <td>-0.136001</td>\n",
       "      <td>0.086525</td>\n",
       "      <td>-0.281031</td>\n",
       "      <td>0.075509</td>\n",
       "      <td>0.262208</td>\n",
       "      <td>0.489894</td>\n",
       "      <td>0.162419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016910</td>\n",
       "      <td>0.018560</td>\n",
       "      <td>-0.088684</td>\n",
       "      <td>-0.273650</td>\n",
       "      <td>-0.239859</td>\n",
       "      <td>0.063156</td>\n",
       "      <td>-0.228324</td>\n",
       "      <td>0.051924</td>\n",
       "      <td>-0.155250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT RATE OFF.</th>\n",
       "      <td>-0.102214</td>\n",
       "      <td>0.039824</td>\n",
       "      <td>-0.216726</td>\n",
       "      <td>-0.016649</td>\n",
       "      <td>0.295497</td>\n",
       "      <td>-0.031002</td>\n",
       "      <td>0.254524</td>\n",
       "      <td>-0.016910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.155134</td>\n",
       "      <td>-0.156552</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>-0.075807</td>\n",
       "      <td>-0.019005</td>\n",
       "      <td>-0.290404</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.121462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT RATE DEF.</th>\n",
       "      <td>-0.286381</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>-0.356844</td>\n",
       "      <td>-0.035310</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.440002</td>\n",
       "      <td>0.174179</td>\n",
       "      <td>0.018560</td>\n",
       "      <td>0.155134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200624</td>\n",
       "      <td>0.057268</td>\n",
       "      <td>-0.317084</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.243076</td>\n",
       "      <td>-0.069698</td>\n",
       "      <td>-0.097462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT% OFF.</th>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>0.345656</td>\n",
       "      <td>0.146895</td>\n",
       "      <td>-0.294047</td>\n",
       "      <td>-0.220110</td>\n",
       "      <td>-0.229168</td>\n",
       "      <td>-0.088684</td>\n",
       "      <td>-0.156552</td>\n",
       "      <td>-0.200624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151693</td>\n",
       "      <td>0.241639</td>\n",
       "      <td>0.097813</td>\n",
       "      <td>0.333594</td>\n",
       "      <td>0.127636</td>\n",
       "      <td>0.204232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT% DEF.</th>\n",
       "      <td>0.084193</td>\n",
       "      <td>0.156899</td>\n",
       "      <td>0.067115</td>\n",
       "      <td>0.117667</td>\n",
       "      <td>-0.126160</td>\n",
       "      <td>-0.207003</td>\n",
       "      <td>-0.093387</td>\n",
       "      <td>-0.273650</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.057268</td>\n",
       "      <td>0.151693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065835</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>0.156471</td>\n",
       "      <td>-0.013544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2P% OFF.</th>\n",
       "      <td>0.529949</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>0.867997</td>\n",
       "      <td>0.079702</td>\n",
       "      <td>-0.152853</td>\n",
       "      <td>-0.237096</td>\n",
       "      <td>-0.190445</td>\n",
       "      <td>-0.239859</td>\n",
       "      <td>-0.075807</td>\n",
       "      <td>-0.317084</td>\n",
       "      <td>0.241639</td>\n",
       "      <td>0.065835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048591</td>\n",
       "      <td>0.331287</td>\n",
       "      <td>0.076194</td>\n",
       "      <td>0.199560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2P% DEF.</th>\n",
       "      <td>-0.034671</td>\n",
       "      <td>0.640749</td>\n",
       "      <td>0.041823</td>\n",
       "      <td>0.882149</td>\n",
       "      <td>-0.148887</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>-0.229249</td>\n",
       "      <td>0.063156</td>\n",
       "      <td>-0.019005</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>0.097813</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>0.048591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>0.131471</td>\n",
       "      <td>-0.271281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3P% OFF.</th>\n",
       "      <td>0.504958</td>\n",
       "      <td>0.046652</td>\n",
       "      <td>0.747324</td>\n",
       "      <td>0.090346</td>\n",
       "      <td>-0.177384</td>\n",
       "      <td>-0.294161</td>\n",
       "      <td>-0.245206</td>\n",
       "      <td>-0.228324</td>\n",
       "      <td>-0.290404</td>\n",
       "      <td>-0.243076</td>\n",
       "      <td>0.333594</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>0.331287</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200114</td>\n",
       "      <td>0.223194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3P% DEF.</th>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.389342</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.575494</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>-0.111957</td>\n",
       "      <td>-0.081738</td>\n",
       "      <td>0.051924</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.069698</td>\n",
       "      <td>0.127636</td>\n",
       "      <td>0.156471</td>\n",
       "      <td>0.076194</td>\n",
       "      <td>0.131471</td>\n",
       "      <td>0.200114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.127391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARTHAG</th>\n",
       "      <td>0.517020</td>\n",
       "      <td>-0.519868</td>\n",
       "      <td>0.260174</td>\n",
       "      <td>-0.279983</td>\n",
       "      <td>-0.137656</td>\n",
       "      <td>-0.041799</td>\n",
       "      <td>0.154509</td>\n",
       "      <td>-0.155250</td>\n",
       "      <td>-0.121462</td>\n",
       "      <td>-0.097462</td>\n",
       "      <td>0.204232</td>\n",
       "      <td>-0.013544</td>\n",
       "      <td>0.199560</td>\n",
       "      <td>-0.271281</td>\n",
       "      <td>0.223194</td>\n",
       "      <td>-0.127391</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ADJ. EFF. OFF.  ADJ. EFF. DEF.  EFF. FG% OFF.  EFF. FG% DEF.  \\\n",
       "ADJ. EFF. OFF.        1.000000       -0.302666       0.628170       0.016115   \n",
       "ADJ. EFF. DEF.       -0.302666        1.000000       0.030741       0.710293   \n",
       "EFF. FG% OFF.         0.628170        0.030741       1.000000       0.111205   \n",
       "EFF. FG% DEF.         0.016115        0.710293       0.111205       1.000000   \n",
       "TURNOVER% OFF.       -0.479529        0.005809      -0.202413      -0.124246   \n",
       "TURNOVER% DEF.       -0.240984       -0.288723      -0.321216      -0.022969   \n",
       "OFF. REB% OFF.        0.161306       -0.268007      -0.284749      -0.228701   \n",
       "OFF. REB% DEF.       -0.136001        0.086525      -0.281031       0.075509   \n",
       "FT RATE OFF.         -0.102214        0.039824      -0.216726      -0.016649   \n",
       "FT RATE DEF.         -0.286381        0.004432      -0.356844      -0.035310   \n",
       "FT% OFF.              0.445124        0.031785       0.345656       0.146895   \n",
       "FT% DEF.              0.084193        0.156899       0.067115       0.117667   \n",
       "2P% OFF.              0.529949       -0.003702       0.867997       0.079702   \n",
       "2P% DEF.             -0.034671        0.640749       0.041823       0.882149   \n",
       "3P% OFF.              0.504958        0.046652       0.747324       0.090346   \n",
       "3P% DEF.              0.092774        0.389342       0.157900       0.575494   \n",
       "BARTHAG               0.517020       -0.519868       0.260174      -0.279983   \n",
       "\n",
       "                TURNOVER% OFF.  TURNOVER% DEF.  OFF. REB% OFF.  \\\n",
       "ADJ. EFF. OFF.       -0.479529       -0.240984        0.161306   \n",
       "ADJ. EFF. DEF.        0.005809       -0.288723       -0.268007   \n",
       "EFF. FG% OFF.        -0.202413       -0.321216       -0.284749   \n",
       "EFF. FG% DEF.        -0.124246       -0.022969       -0.228701   \n",
       "TURNOVER% OFF.        1.000000        0.215373        0.347886   \n",
       "TURNOVER% DEF.        0.215373        1.000000        0.192090   \n",
       "OFF. REB% OFF.        0.347886        0.192090        1.000000   \n",
       "OFF. REB% DEF.        0.262208        0.489894        0.162419   \n",
       "FT RATE OFF.          0.295497       -0.031002        0.254524   \n",
       "FT RATE DEF.          0.142056        0.440002        0.174179   \n",
       "FT% OFF.             -0.294047       -0.220110       -0.229168   \n",
       "FT% DEF.             -0.126160       -0.207003       -0.093387   \n",
       "2P% OFF.             -0.152853       -0.237096       -0.190445   \n",
       "2P% DEF.             -0.148887        0.022842       -0.229249   \n",
       "3P% OFF.             -0.177384       -0.294161       -0.245206   \n",
       "3P% DEF.             -0.002125       -0.111957       -0.081738   \n",
       "BARTHAG              -0.137656       -0.041799        0.154509   \n",
       "\n",
       "                OFF. REB% DEF.  FT RATE OFF.  FT RATE DEF.  FT% OFF.  \\\n",
       "ADJ. EFF. OFF.       -0.136001     -0.102214     -0.286381  0.445124   \n",
       "ADJ. EFF. DEF.        0.086525      0.039824      0.004432  0.031785   \n",
       "EFF. FG% OFF.        -0.281031     -0.216726     -0.356844  0.345656   \n",
       "EFF. FG% DEF.         0.075509     -0.016649     -0.035310  0.146895   \n",
       "TURNOVER% OFF.        0.262208      0.295497      0.142056 -0.294047   \n",
       "TURNOVER% DEF.        0.489894     -0.031002      0.440002 -0.220110   \n",
       "OFF. REB% OFF.        0.162419      0.254524      0.174179 -0.229168   \n",
       "OFF. REB% DEF.        1.000000     -0.016910      0.018560 -0.088684   \n",
       "FT RATE OFF.         -0.016910      1.000000      0.155134 -0.156552   \n",
       "FT RATE DEF.          0.018560      0.155134      1.000000 -0.200624   \n",
       "FT% OFF.             -0.088684     -0.156552     -0.200624  1.000000   \n",
       "FT% DEF.             -0.273650      0.003917      0.057268  0.151693   \n",
       "2P% OFF.             -0.239859     -0.075807     -0.317084  0.241639   \n",
       "2P% DEF.              0.063156     -0.019005     -0.000367  0.097813   \n",
       "3P% OFF.             -0.228324     -0.290404     -0.243076  0.333594   \n",
       "3P% DEF.              0.051924      0.008773     -0.069698  0.127636   \n",
       "BARTHAG              -0.155250     -0.121462     -0.097462  0.204232   \n",
       "\n",
       "                FT% DEF.  2P% OFF.  2P% DEF.  3P% OFF.  3P% DEF.   BARTHAG  \n",
       "ADJ. EFF. OFF.  0.084193  0.529949 -0.034671  0.504958  0.092774  0.517020  \n",
       "ADJ. EFF. DEF.  0.156899 -0.003702  0.640749  0.046652  0.389342 -0.519868  \n",
       "EFF. FG% OFF.   0.067115  0.867997  0.041823  0.747324  0.157900  0.260174  \n",
       "EFF. FG% DEF.   0.117667  0.079702  0.882149  0.090346  0.575494 -0.279983  \n",
       "TURNOVER% OFF. -0.126160 -0.152853 -0.148887 -0.177384 -0.002125 -0.137656  \n",
       "TURNOVER% DEF. -0.207003 -0.237096  0.022842 -0.294161 -0.111957 -0.041799  \n",
       "OFF. REB% OFF. -0.093387 -0.190445 -0.229249 -0.245206 -0.081738  0.154509  \n",
       "OFF. REB% DEF. -0.273650 -0.239859  0.063156 -0.228324  0.051924 -0.155250  \n",
       "FT RATE OFF.    0.003917 -0.075807 -0.019005 -0.290404  0.008773 -0.121462  \n",
       "FT RATE DEF.    0.057268 -0.317084 -0.000367 -0.243076 -0.069698 -0.097462  \n",
       "FT% OFF.        0.151693  0.241639  0.097813  0.333594  0.127636  0.204232  \n",
       "FT% DEF.        1.000000  0.065835  0.046616  0.037846  0.156471 -0.013544  \n",
       "2P% OFF.        0.065835  1.000000  0.048591  0.331287  0.076194  0.199560  \n",
       "2P% DEF.        0.046616  0.048591  1.000000 -0.001975  0.131471 -0.271281  \n",
       "3P% OFF.        0.037846  0.331287 -0.001975  1.000000  0.200114  0.223194  \n",
       "3P% DEF.        0.156471  0.076194  0.131471  0.200114  1.000000 -0.127391  \n",
       "BARTHAG        -0.013544  0.199560 -0.271281  0.223194 -0.127391  1.000000  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking correlations because one of the assumptions of logistic regression is no perfect multicollinearity among independent variables.\n",
    "X.corr(method='pearson', min_periods=1, numeric_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9cab2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop '2P% OFF.', 'EFF. FG% DEF.', '3P% OFF.', '2P% DEF.' because they are highly correlated \n",
    "X= data.drop(['RK','TEAM','CONF', 'R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'R64', '2P% OFF.', 'EFF. FG% DEF.', '3P% OFF.', '2P% DEF.'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4aa7ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data\n",
    "X= scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bba2ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the round of 32\n",
    "y = data['R32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "37a7e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty vector of length of Complete Combined Files .xlsx to store original indexs of teams\n",
    "indices = np.arange(192)\n",
    "\n",
    "#include indices_train and indices_test to capture the original index \n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, random_state=1, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3495befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the logistic regression model on previous years combined dataset\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3660a2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77        31\n",
      "           1       0.72      0.78      0.75        27\n",
      "\n",
      "    accuracy                           0.76        58\n",
      "   macro avg       0.76      0.76      0.76        58\n",
      "weighted avg       0.76      0.76      0.76        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faaf132",
   "metadata": {},
   "source": [
    "The logistic regression model predicted with 0.76 accuracy. We continued to look at the sweet 16 and elite 8 and the accuracy continued to be high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ef368bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at how well regression does with 2024 data as the test data\n",
    "\n",
    "#reading in 2024 data\n",
    "data24 = pd.read_csv('2024 Final Total Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bceca5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the same columns in the 2024 data\n",
    "X24= data24.drop(['RK','TEAM','CONF', 'R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'R64', '2P% OFF.', 'EFF. FG% DEF.', '3P% OFF.', '2P% DEF.'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10a68f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the 2024 data\n",
    "X24 = scale(X24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c419d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What we are predicting \n",
    "y = data['R32']\n",
    "y24 = data24['R32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05dc8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the test (past years) train (2024 data)\n",
    "X_train = X\n",
    "X_test = X24\n",
    "\n",
    "y_train = y\n",
    "y_test = y24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "414ef682",
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d92b43e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65        32\n",
      "           1       0.65      0.69      0.67        32\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.66      0.66      0.66        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef8004",
   "metadata": {},
   "source": [
    "The accuracy went down a little when using the 2024 data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21002c56",
   "metadata": {},
   "source": [
    "### SVM exploratory analysis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4504d73b",
   "metadata": {},
   "source": [
    "### KNN exploratory analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604a003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77745769",
   "metadata": {},
   "source": [
    "### Decision tree exploratory analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a24b9e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in 2009, 2016, 2017 data\n",
    "data = pd.read_excel('Complete Combined Files .xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3ae69479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the outcome columns\n",
    "X = data.drop(columns = ['RK','TEAM','CONF', 'R64','R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP'], axis = 1)\n",
    "\n",
    "#predicting the round of 32 winners\n",
    "y = data['R32']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43004af",
   "metadata": {},
   "source": [
    "NEED TO DO: SUMMARIZE EXPLORATORY ANALYSIS AND WHY WE CHOSE TO MOVE FORWARD WITH SVM AND KNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f5c45",
   "metadata": {},
   "source": [
    "## Analysis Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728d7d57",
   "metadata": {},
   "source": [
    "After our exploratory analysis KNN, logistic regression, and SVM all performed similarly. We decided to move forward with KNN and SVM in our final analysis to see which is better at predicting the winners that advance from the round of 64 to the round of 32 and from the round of 32 to the sweet 16. In addition, we will look atwhich model predicts the most correct teams in each round. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f76cdd",
   "metadata": {},
   "source": [
    "### SVM exploratory analysis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098cdcab",
   "metadata": {},
   "source": [
    "Be sure to explain how you change C and general method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de36ac",
   "metadata": {},
   "source": [
    "### KNN exploratory analysis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52e782",
   "metadata": {},
   "source": [
    "Be sure to explain how you change K and general method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c80173",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304501c",
   "metadata": {},
   "source": [
    "Explain the accuracy of each round and the teams the survived the longest and how that compares to the actual tournament bracket. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cffd38b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b4b750",
   "metadata": {},
   "source": [
    "Scaling the data did not help\n",
    "\n",
    "It seems like many classification models perform well on this type of data. The decision tree did not. \n",
    "\n",
    "CHaing the C and number of K helped us fine tune the model each round. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d1ef1",
   "metadata": {},
   "source": [
    "## Ethical Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b13256b",
   "metadata": {},
   "source": [
    "Our ethical considerations include\n",
    "\n",
    "1. Impact on the sport itself \n",
    "    \n",
    "Sports are something that are supposed to provide entertainment to people and the individuals that play them typically make a career out of them. Creating a data processing method takes away from players achievements and turns everything into one big statistic, potentially creating ignorance to athletes accomplishments and hard work that has gotten them to this point in their career.\n",
    "    \n",
    "   \n",
    "2. Inaccessibility to technology \n",
    "\n",
    "It is important to recognize that not everyone that enjoys March Madness has access to a computer, limiting their ability to create a predictive model that could support their decisions when creating their bracket.\n",
    "\n",
    "\n",
    "3. Bracket Competitions\n",
    "\n",
    "Using the predictive model in a bracket competition may be unethical if the others in the bracket group are not aware. This could be especially problematic if money is involved and an individual is not upfront about how their bracket was completed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a5f79",
   "metadata": {},
   "source": [
    "# Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc65dfdb",
   "metadata": {},
   "source": [
    "In summary, we started by coming up with a topic we were all interested in. We all enjoy the march madness tournament and were excited to put our data science skills to the test on predicting winners in the tournament. Next, we looked for basketball stats that we could use in our model. Once we had data, we cleaned it so we could look at descriptive statistics and make sure the data was clean and accurate. We needed to do some work to get the data in the format we needed to have training and testing data. Finally, we ran KNN, SVM, decision tree, and logistic regression models to see which predicted the winners the best. It appears that logistic regression, KNN, and SVM all perform similarly but for us SVM performed the best. We were able to predict â€¦â€¦â€¦FINISH THIS PART"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
